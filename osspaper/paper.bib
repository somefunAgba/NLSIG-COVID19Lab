
@article{abdulmajeedOnlineForecastingCovid192020,
  title = {Online {{Forecasting Of Covid}}-19 {{Cases In Nigeria Using Limited Data}}},
  author = {Abdulmajeed, Kabir and Adeleke, Monsuru and Popoola, Labode},
  year = {2020},
  month = jun,
  volume = {30},
  pages = {105683},
  issn = {2352-3409},
  doi = {10.1016/j.dib.2020.105683},
  abstract = {The novel Coronavirus disease (COVID-19) was first identified in Wuhan, China in December 2019 but later spread to other parts of the world. The disease as at the point of writing this paper has been declared a pandemic by the World Health Organization (WHO). The application of mathematical models, artificial intelligence, big data, and similar methodologies are potential tools to predict the extent of the spread and effectiveness of containment strategies to stem the transmission of this disease. In societies with constrained data infrastructures, modeling and forecasting COVID-19 becomes an extremely difficult endeavor. Nonetheless, we propose an online forecasting mechanism that streams data from the Nigeria Center for Disease Control to update the parameters of an ensemble model which in turn provides updated COVID-19 forecasts every 24 hours. The ensemble combines an Auto-Regressive Integrated Moving Average model (ARIMA), Prophet - an additive regression model developed by Facebook, and a Holt-Winters Exponential Smoothing model combined with Generalized Autoregressive Conditional Heteroscedasticity (GARCH). The outcomes of these efforts are expected to provide academic thrust in guiding the policymakers in the deployment of containment strategies and/or assessment of containment interventions in stemming the spread of the disease in Nigeria},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\64XVFGTS\\Abdulmajeed et al. - 2020 - ONLINE FORECASTING OF COVID-19 CASES IN NIGERIA US.pdf:application/pdf},
  journal = {Data in Brief},
  language = {en},
  timestamp = {2020-10-20T17:23:30Z}
}

@article{abdulrahmanSimCOVIDOpenSourceSimulation2020,
  title = {{{SimCOVID}}: {{Open}}-{{Source Simulation Programs}} for the {{COVID}}-19 {{Outbreak}}},
  shorttitle = {{{SimCOVID}}},
  author = {Abdulrahman, Ismael Khorshed},
  year = {2020},
  month = jun,
  pages = {2020.04.13.20063354},
  publisher = {{Cold Spring Harbor Laboratory Press}},
  doi = {10.1101/2020.04.13.20063354},
  abstract = {{$<$}p{$>$}This paper presents open-source computer simulation programs developed for simulating, tracking, and estimating the COVID-19 outbreak. The programs consist of two separate parts: one set of programs built in Simulink with a block diagram display, and another one coded in MATLAB as scripts. The mathematical model used in this package is the SIR, SEIR, and SEIRD models represented by a set of differential-algebraic equations. It can be easily modified to develop new models for the problem. A generalized method is adopted to simulate worldwide outbreaks in an efficient, fast, and simple way. To get a good tracking of the virus spread, a sum of sigmoid functions was proposed to capture any dynamic changes in the data. The parameters used for the input (infection and recovery rate functions) are computed using the parameter estimation tool in MATLAB. Several statistic methods were applied for the rate function including linear, mean, root-mean-square, and standard deviation. In addition, an adaptive neuro-fuzzy inference system is employed and proposed to train the model and predict its output. The programs can be used as a teaching tool and for research studies.{$<$}/p{$>$}},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\VAU72S8T\\Abdulrahman - 2020 - SimCOVID Open-Source Simulation Programs for the .pdf:application/pdf},
  journal = {medRxiv},
  language = {en},
  timestamp = {2020-10-22T13:28:03Z}
}

@book{agarwalDifferenceEquationsInequalities2000,
  title = {Difference {{Equations}} and {{Inequalities}}: {{Theory}}, {{Methods}}, and {{Applications}}},
  shorttitle = {Difference {{Equations}} and {{Inequalities}}},
  author = {Agarwal, Ravi P.},
  year = {2000},
  month = jan,
  publisher = {{CRC Press}},
  abstract = {A study of difference equations and inequalities. This second edition offers real-world examples and uses of difference equations in probability theory, queuing and statistical problems, stochastic time series, combinatorial analysis, number theory, geometry, electrical networks, quanta in radiation, genetics, economics, psychology, sociology, and},
  googlebooks = {xMaAqOWMgXkC},
  isbn = {978-1-4200-2702-0},
  language = {en},
  timestamp = {2019-08-04T17:21:08Z}
}

@article{al-araji_adaptive_2019,
  title = {An Adaptive Swing-up Sliding Mode Controller Design for a Real Inverted Pendulum System Based on {{Culture}}-{{Bees}} Algorithm},
  author = {{Al-Araji}, Ahmed S.},
  year = {2019},
  month = jan,
  volume = {45},
  pages = {45--56},
  issn = {0947-3580},
  doi = {10.1016/j.ejcon.2018.12.001},
  abstract = {This paper presents a new design and implementation of an adaptive swing-up control algorithm for a real inverted pendulum system. The main core of the control algorithm is a sliding mode technique with the Lyapunov stability method. The goal of the proposed adaptive swing-up controller is to get the optimal force control action for the inverted pendulum in the real-time in order to precisely and quickly swing the pendulum up to the inverted position. An on-line auto-tuning hybrid intelligent algorithm based on Culture-Bees algorithms is carried out as a stable and robust algorithm to obtain and adjust the control parameters for the proposed controller. To eliminate the chattering effect of the fast switching surface, the sigmoid function is used as a Signum function for reducing the amplitude of the output function. The numerical simulation results in MATLAB and the experimental work in LabVIEW illustrate the improved performance of the adaptive swing-up controller in terms of robust performance and adaptation effectiveness that minimized the pendulum angle error to a zero value and obtained the best force control action for the pendulum cart, in addition to reducing the fitness evaluation number. These results were confirmed by a comparative study with different nonlinear controller types.},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\7JFTKFC5\\Al-Araji - 2019 - An adaptive swing-up sliding mode controller desig.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\J259FG8P\\S0947358018300189.html:text/html},
  journal = {European Journal of Control},
  timestamp = {2019-05-12T03:57:05Z}
}

@book{astromComputercontrolledSystemsTheory2013,
  title = {Computer-Controlled Systems: Theory and Design},
  author = {{\AA}str{\"o}m, Karl J. and Wittenmark, Bj{\"o}rn},
  year = {2013},
  publisher = {{Courier Corporation}},
  isbn = {0-486-28404-2},
  timestamp = {2019-03-09T06:33:35Z}
}

@inbook{bacaerVerhulstLogisticEquation2011,
  title = {Verhulst and the Logistic Equation (1838)},
  booktitle = {A {{Short History}} of {{Mathematical Population Dynamics}}},
  author = {Baca{\"e}r, Nicolas},
  year = {2011},
  pages = {35--39},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/978-0-85729-115-8_6},
  collaborator = {Baca{\"e}r, Nicolas},
  file = {Bacaër - 2011 - Verhulst and the logistic equation (1838).pdf:C\:\\Users\\SomefunAgba\\Zotero\\storage\\74QJD77C\\Bacaër - 2011 - Verhulst and the logistic equation (1838).pdf:application/pdf},
  isbn = {978-0-85729-114-1 978-0-85729-115-8},
  language = {en},
  timestamp = {2020-11-29T18:34:39Z}
}

@inproceedings{baiDeepEquilibriumModels2019,
  title = {Deep Equilibrium Models},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
  year = {2019},
  pages = {690--701},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\TJH2TX7M\\Bai et al. - 2019 - Deep equilibrium models.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\MHXWZZ2X\\01386bd6d8e091c2ab4c7c7de644d37b-Abstract.html:text/html},
  timestamp = {2020-11-28T06:30:39Z}
}

@unpublished{barkerLogisticFunctionComplementary2020,
  title = {Logistic Function and Complementary {{Fermi}} Function for Simple Modelling of the {{COVID}}-19 Pandemic: Tutorial Notes},
  shorttitle = {Logistic Function and Complementary {{Fermi}} Function for Simple Modelling of the {{COVID}}-19 Pandemic},
  author = {Barker, John and Watt, James},
  year = {2020},
  month = mar,
  doi = {10.13140/RG.2.2.22509.95202},
  abstract = {Some tutorial notes on the three parameter logistic function and its relation to the Fermi function for simple modelling pandemics phenomena. The WHO data for the number of cases of infection with the COVID-19 virus for multiple countries as a function of time is fitted very well by a discretised logistic function. The rate of infection may be modelled by the derivative of the logistics function. More complex phenomena such as the appearance of fresh outburst of infection may be treated by using a superposition of logistic functions. The data for China and Italy are analysed.These notes are intended for undergraduates, graduate students who may find pleasure in the ability of applied mathematics and physics to shed light on the complexities of the real world.},
  timestamp = {2020-10-20T17:22:34Z}
}

@book{bassoDesigningControlLoops2012,
  title = {Designing {{Control Loops}} for {{Linear}} and {{Switching Power Supplies}}: {{A Tutorial Guide}}},
  shorttitle = {Designing {{Control Loops}} for {{Linear}} and {{Switching Power Supplies}}},
  author = {Basso, Christophe P.},
  year = {2012},
  publisher = {{Artech House}},
  abstract = {Loop control is an essential area of electronics engineering that todays professionals need to master. Rather than delving into extensive theory, this practical book focuses on what you really need to know for compensating or stabilizing a given control system. You can turn instantly to practical sections with numerous design examples and ready-made formulas to help you with your projects in the field. You also find coverage of the underpinnings and principles of control loops so you can gain a more complete understanding of the material. This authoritative volume explains how to conduct analysis of control systems and provides extensive details on practical compensators. It helps you measure your system, showing how to verify if a prototype is stable and features enough design margin. Moreover, you learn how to secure high-volume production by bench-verified safety margins.},
  googlebooks = {PpvqwxaE1SMC},
  isbn = {978-1-60807-557-7},
  language = {en},
  timestamp = {2019-08-16T11:13:06Z}
}

@article{batistaEstimationStateCorona2020,
  title = {Estimation of a State of {{Corona}} 19 Epidemic in {{August}} 2020 by Multistage Logistic Model: A Case of {{EU}}, {{USA}}, and {{World}} ({{Update September}} 2020)},
  shorttitle = {Estimation of a State of {{Corona}} 19 Epidemic in {{August}} 2020 by Multistage Logistic Model},
  author = {Batista, Milan},
  year = {2020},
  month = oct,
  pages = {2020.08.31.20185165},
  publisher = {{Cold Spring Harbor Laboratory Press}},
  doi = {10.1101/2020.08.31.20185165},
  abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}The article provides an estimate of the size and duration of the Covid-19 epidemic in August 2020 and September 2020 for the European Union (EU), the United States (US), and the World using a multistage logistical epidemiological model.{$<$}/p{$>$}},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\UDEQ4R98\\Batista - 2020 - Estimation of a state of Corona 19 epidemic in Aug.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\VVP9HQY3\\2020.08.31.html:text/html;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\YVP2BUQA\\2020.08.31.html:text/html},
  journal = {medRxiv},
  language = {en},
  timestamp = {2020-11-29T12:13:15Z}
}

@article{bejanConstructalLawOrigin2011,
  title = {The Constructal Law Origin of the Logistics {{S}} Curve},
  author = {Bejan, A. and Lorente, S.},
  year = {2011},
  month = jul,
  volume = {110},
  pages = {024901},
  publisher = {{American Institute of Physics}},
  issn = {0021-8979},
  doi = {10.1063/1.3606555},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\V33RIHE6\\1.html:text/html},
  journal = {Journal of Applied Physics},
  number = {2},
  timestamp = {2020-11-30T06:34:14Z}
}

@patent{bekasFastEnergyefficientExponential2016,
  title = {Fast, Energy-Efficient Exponential Computations in Simd Architectures},
  author = {Bekas, Konstantinos and Curioni, Alessandro and Ineichen, Yves and Malossi, Adelmo Cristiano Innocenza},
  year = {2016},
  month = may,
  url = {https://patents.google.com/patent/US20160124713A1/en},
  urldate = {2020-09-24},
  assignee = {International Business Machines Corp},
  file = {Fulltext PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ZPZ4JE2X\\Bekas et al. - 2016 - Fast, energy-efficient exponential computations in.pdf:application/pdf},
  nationality = {US},
  number = {US20160124713A1},
  timestamp = {2020-09-24T22:51:38Z}
}

@article{bengioLearningLongtermDependencies1994,
  title = {Learning Long-Term Dependencies with Gradient Descent Is Difficult},
  author = {Bengio, Y. and Simard, P. and Frasconi, P.},
  year = {1994},
  month = mar,
  volume = {5},
  pages = {157--166},
  issn = {1941-0093},
  doi = {10.1109/72.279181},
  abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.{$<>$}},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\CS6LF8IQ\\279181.html:text/html},
  journal = {IEEE Transactions on Neural Networks},
  number = {2},
  timestamp = {2020-10-20T10:51:38Z}
}

@book{bertsekasConvexOptimizationAlgorithms2015a,
  title = {Convex {{Optimization Algorithms}} (for {{Algorithmix}})},
  author = {Bertsekas, Dimitri P.},
  year = {2015},
  edition = {First},
  publisher = {{Athena Scientific}},
  url = {http://gen.lib.rus.ec/book/index.php?md5=ff721c4982375adcc6734a99de0d584d},
  urldate = {2020-11-29},
  isbn = {978-1-886529-28-1},
  timestamp = {2020-11-29T17:51:44Z}
}

@book{boydConvexOptimization2009,
  title = {Convex {{Optimization}}},
  author = {Boyd, S. and Vandenberghe, L.},
  year = {2009},
  edition = {(corr.)},
  publisher = {{Cambridge}},
  url = {http://gen.lib.rus.ec/book/index.php?md5=63adacbf735bf4ec4a255c90cf09435f},
  urldate = {2020-11-29},
  isbn = {978-0-521-83378-3},
  timestamp = {2020-11-29T17:47:56Z}
}

@book{boydLinearControllerDesign1991,
  title = {Linear Controller Design: Limits of Performance},
  shorttitle = {Linear Controller Design},
  author = {Boyd, Stephen P. and Barratt, Craig H.},
  year = {1991},
  publisher = {{Prentice Hall Englewood Cliffs, NJ}},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\J4P9XJA2\\Boyd and Barratt - 1991 - Linear controller design limits of performance.pdf:application/pdf},
  timestamp = {2019-08-16T10:36:24Z}
}

@book{boydMultiPeriodTradingConvex2017,
  title = {Multi-{{Period Trading}} via {{Convex Optimization}}},
  author = {Boyd, Stephen},
  year = {2017},
  publisher = {{NOW Publishers}},
  url = {http://gen.lib.rus.ec/book/index.php?md5=0890A182A35E6362EBA0FABAB0B0D34C},
  urldate = {2020-11-29},
  timestamp = {2020-11-29T17:52:51Z}
}

@book{brinkhuisConvexAnalysisOptimization2020,
  title = {Convex {{Analysis}} for {{Optimization}}: {{A Unified Approach}}},
  shorttitle = {Convex {{Analysis}} for {{Optimization}}},
  author = {Brinkhuis, Jan},
  year = {2020},
  edition = {1 ed. 2020},
  publisher = {{Springer Nature}},
  url = {http://gen.lib.rus.ec/book/index.php?md5=6F13176345A2E1413671CFE6CD50BD8E},
  urldate = {2020-11-29},
  isbn = {978-3-030-41803-8},
  series = {Graduate {{Texts}} in {{Operations Research}}},
  timestamp = {2020-11-29T17:57:54Z}
}

@article{cadiouSlidingModePosition1995,
  title = {Sliding {{Mode Position Control}} of an {{Actuator}} with {{Backlash}} and {{Coulomb Friction}}},
  author = {Cadiou, J. C. and M'Sirdi, N. K. and Blazevic, P.},
  year = {1995},
  month = jul,
  volume = {28},
  pages = {103--108},
  issn = {1474-6670},
  doi = {10.1016/S1474-6670(17)45445-0},
  abstract = {R\'esum\'e Cet article pr\'esente une application exp\'erimentale d'une commande \`a structure variable utilisant une approche par mode de glissement sur un actionneur \'electrique original pr\'esentant des jeux et des frottements secs. De bonnes performances et une grande robustesse face aux jeux ont \'et\'e obtenues. This paper presents an experimental application of the variable structure control using the sliding mode technique to control an original actuator with backlash and Coulomb friction. Good robustness performances to reject the backlash effect, and quick responses are obtained.},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\CGRNANZW\\Cadiou et al. - 1995 - Sliding Mode Position Control of an Actuator with .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ISQU25DP\\S1474667017454450.html:text/html},
  journal = {IFAC Proceedings Volumes},
  number = {8},
  series = {{{IFAC Conference}} on {{System Structure}} and {{Control}} 1995, {{Nantes}}, {{France}}, 5-7 {{July}} 1995},
  timestamp = {2019-08-01T08:40:07Z}
}

@article{campos_nonlinear_2019,
  title = {A Nonlinear Controller Based on Saturation Functions with Variable Parameters to Stabilize an {{AUV}}},
  author = {Campos, E. and Monroy, J. and Abundis, H. and Chemori, A. and Creuze, V. and Torres, J.},
  year = {2019},
  month = jan,
  volume = {11},
  pages = {211--224},
  issn = {2092-6782},
  doi = {10.1016/j.ijnaoe.2018.04.002},
  abstract = {This paper deals with a nonlinear controller based on saturation functions with variable parameters for set-point regulation and trajectory tracking control of an Autonomous Underwater Vehicle (AUV). In many cases, saturation functions with constant parameters are used to limit the input signals generated by a classical PD (Proportional-Derivative) controller to avoid damaging the actuators; however this abrupt bounded harms the performance of the controller. We, therefore, propose to replace the conventional saturation function, with constant parameters, by a saturation function with variable parameters to limit the signals of a PD controller, which is the base of the nonlinear PD with gravitational/buoyancy compensation and the nonlinear PD~+~controllers that we propose in this paper. Consequently, the mathematical model is obtained, considering the featuring operation of the underwater vehicle LIRMIA 2, to do the stability analysis of the closed-loop system with the proposed nonlinear controllers using the Lyapunov arguments. The experimental results show the performance of an AUV (LIRMIA 2) for the depth control problems in the case of set-point regulation and trajectory tracking control.},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\MMIGVBZQ\\Campos et al. - 2019 - A nonlinear controller based on saturation functio.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\Q9H2ZSE3\\S2092678217300249.html:text/html},
  journal = {International Journal of Naval Architecture and Ocean Engineering},
  number = {1},
  timestamp = {2019-05-11T03:01:44Z}
}

@article{carlile_improving_2017,
  title = {Improving {{Deep Learning}} by {{Inverse Square Root Linear Units}} ({{ISRLUs}})},
  author = {Carlile, Brad and Delamarter, Guy and Kinney, Paul and Marti, Akiko and Whitney, Brian},
  year = {2017},
  month = oct,
  url = {http://arxiv.org/abs/1710.09967},
  urldate = {2019-05-11},
  abstract = {We introduce the "inverse square root linear unit" (ISRLU) to speed up learning in deep neural networks. ISRLU has better performance than ELU but has many of the same benefits. ISRLU and ELU have similar curves and characteristics. Both have negative values, allowing them to push mean unit activation closer to zero, and bring the normal gradient closer to the unit natural gradient, ensuring a noise-robust deactivation state, lessening the over fitting risk. The significant performance advantage of ISRLU on traditional CPUs also carry over to more efficient HW implementations on HW/SW codesign for CNNs/RNNs. In experiments with TensorFlow, ISRLU leads to faster learning and better generalization than ReLU on CNNs. This work also suggests a computationally efficient variant called the "inverse square root unit" (ISRU) which can be used for RNNs. Many RNNs use either long short-term memory (LSTM) and gated recurrent units (GRU) which are implemented with tanh and sigmoid activation functions. ISRU has less com- putational complexity but still has a similar curve to tanh and sigmoid.},
  archivePrefix = {arXiv},
  eprint = {1710.09967},
  eprinttype = {arxiv},
  file = {arXiv\:1710.09967 PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\XGQZY6MY\\Carlile et al. - 2017 - Improving Deep Learning by Inverse Square Root Lin.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\M7K7ISJS\\1710.html:text/html},
  journal = {arXiv:1710.09967 [cs]},
  primaryClass = {cs},
  timestamp = {2019-05-11T02:34:53Z}
}

@article{chalanga_output_2019,
  title = {Output Regulation Using New Sliding Surface with an Implementation on Inverted Pendulum System},
  author = {Chalanga, Asif and Patil, Machhindranath and Bandyopadhyay, Bijnan and Arya, Hemendra},
  year = {2019},
  month = jan,
  volume = {45},
  pages = {85--91},
  issn = {0947-3580},
  doi = {10.1016/j.ejcon.2018.09.011},
  abstract = {In this paper constant reference output tracking is achieved using second order sliding mode (SOSM) control. To achieve tracking a new sliding surface is proposed and to ensure sliding motion super-twisting control (STC) is employed. The proposed sliding surface is more general, and it can be used for constant reference tracking in both minimum phase and non-minimum phase systems. The proposed method is validated on the unstable non-minimum phase inverted pendulum system and also the results are compared with the first order sliding mode control (SMC) in simulation and experimentally both.},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\USWER3QR\\Chalanga et al. - 2019 - Output regulation using new sliding surface with a.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\R49W8W84\\S0947358018301249.html:text/html},
  journal = {European Journal of Control},
  timestamp = {2019-05-12T03:58:15Z}
}

@inproceedings{che-weilinDigitalCircuitDesign2008,
  title = {A Digital Circuit Design of Hyperbolic Tangent Sigmoid Function for Neural Networks},
  booktitle = {2008 {{IEEE International Symposium}} on {{Circuits}} and {{Systems}}},
  author = {{Che-Wei Lin} and {Jeen-Shing Wang}},
  year = {2008},
  month = may,
  pages = {856--859},
  doi = {10.1109/ISCAS.2008.4541553},
  abstract = {This paper presents a digital circuit design approach for a commonly used activation function, hyperbolic tangent sigmoid functions, for neural networks. Our design concept for such a nonlinear function is to approximate the function of its first-order derivative by piece-wise linear functions first, then to obtain the estimate of the original function by integrating the approximated function of the first-order derivative by a digital circuit. The average error and maximum error of the proposed approximation approach are in the order of 10-3 and 10-2, respectively in the software simulation. The hardware implementation of the proposed method consumes only one multiplication and one addition/subtraction ALU with the aid of resource sharing. The performance of our circuit has been validated by a neural network for a system identification problem in the software simulation.},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\8579KINL\\4541553.html:text/html},
  timestamp = {2019-07-30T06:06:53Z}
}

@book{chenFeedbackNonlinearDistributed2018,
  title = {Feedback, {{Nonlinear}}, and {{Distributed Circuits}}},
  author = {Chen, WaiKai},
  year = {2018},
  month = oct,
  publisher = {{CRC Press}},
  abstract = {Upon its initial publication, the Handbook of Circuits and Filters broke new ground. It quickly became the resource for comprehensive coverage of issues and practical information that can be put to immediate use. Not content to rest on his laurels, editor Wai-kai Chen divided the second edition into volumes, making the information easily accessible and digestible. In the third edition, these volumes have been revised, updated, and expanded so that they continue to provide solid coverage of standard practices and enlightened perspectives on new and emerging techniques. Feedback, Nonlinear, and Distributed Circuits draws together international contributors who discuss feedback amplifier theory and then move on to explore feedback amplifier configurations. They develop Bode's feedback theory as an example of general feedback theory. The coverage then moves on to the importance of complementing numerical analysis with qualitative analysis to get a global picture of a circuit's performance. After reviewing a wide range of approximation techniques and circuit design styles for discreet and monolithic circuits, the book presents a comprehensive description of the use of piecewise-linear methods in modeling, analysis, and structural properties of nonlinear circuits highlighting the advantages. It describes the circuit modeling in the frequency domain of uniform MTL based on the Telegrapher's equations and covers frequency and time domain experimental characterization techniques for uniform and nonuniform multiconductor structures.  This volume will undoubtedly take its place as the engineer's first choice in looking for solutions to problems encountered in the analysis and behavior predictions of circuits and filters.},
  googlebooks = {W0dPWAaRx6kC},
  isbn = {978-1-4200-5882-6},
  language = {en},
  timestamp = {2020-09-26T16:15:59Z}
}

@inproceedings{Chibole2017PerformanceAO,
  title = {Performance {{Analysis}} of the {{Sigmoid}} and {{Fibonacci Activation Functions}} in {{NGA Architecture}} for a {{Generalized Independent Component Analysis}}},
  author = {Chibole, James Paul},
  year = {2017},
  timestamp = {2019-07-30T06:15:12Z}
}

@inproceedings{chowComparisonPerformanceEmerging1992a,
  title = {On the Comparison of the Performance of Emerging and Conventional Control Techniques for {{DC}} Motor Velocity and Position Control},
  booktitle = {And {{Automation Proceedings}} of the 1992 {{International Conference}} on {{Industrial Electronics}}, {{Control}}, {{Instrumentation}}},
  author = {Chow, M. and Menozzi, A. and Holcomb, F.},
  year = {1992},
  month = nov,
  pages = {1008-1013 vol.2},
  doi = {10.1109/IECON.1992.254474},
  abstract = {The emerging control techniques which utilize artificial neural networks and fuzzy logic are compared with conventional proportional-integral (PI) control for the velocity and position control of a DC motor. The performance of the control techniques is compared in terms of rise time, settling time, tracking error, smoothness of response, and robustness with respect to modeling errors and disturbances. The control design process and implementation requirements are also discussed.{$<>$}},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\8L5ZMFVW\\254474.html:text/html},
  timestamp = {2019-08-17T04:48:27Z}
}

@article{chowellNovelSubepidemicModeling2019,
  title = {A Novel Sub-Epidemic Modeling Framework for Short-Term Forecasting Epidemic Waves},
  author = {Chowell, Gerardo and Tariq, Amna and Hyman, James M.},
  year = {2019},
  month = aug,
  volume = {17},
  pages = {164},
  issn = {1741-7015},
  doi = {10.1186/s12916-019-1406-6},
  abstract = {Simple phenomenological growth models can be useful for estimating transmission parameters and forecasting epidemic trajectories. However, most existing phenomenological growth models only support single-peak outbreak dynamics whereas real epidemics often display more complex transmission trajectories.},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\AVN59TMJ\\Chowell et al. - 2019 - A novel sub-epidemic modeling framework for short-.pdf:application/pdf},
  journal = {BMC Medicine},
  number = {1},
  timestamp = {2020-11-29T12:06:04Z}
}

@article{christopoulosEfficientIdentificationInflection2016,
  title = {On the Efficient Identification of an Inflection Point},
  author = {Christopoulos, Demetris T.},
  year = {2016},
  volume = {6},
  journal = {International Journal of Mathematics and Scientific Computing,(ISSN: 2231-5330)},
  number = {1},
  timestamp = {2020-10-27T00:21:26Z}
}

@article{christopoulosNovelApproachEstimating2020,
  title = {A {{Novel Approach}} for {{Estimating}} the {{Final Outcome}} of {{Global Diseases Like COVID}}-19},
  author = {Christopoulos, Demetris T.},
  year = {2020},
  month = jul,
  pages = {2020.07.03.20145672},
  publisher = {{Cold Spring Harbor Laboratory Press}},
  doi = {10.1101/2020.07.03.20145672},
  abstract = {{$<$}p{$>$}The existence of a universal law which maps the bell curve of daily cases to a sigmoid curve for cumulative ones is used for making robust estimations about the final outcome of a disease. Computations of real time effective reproduction rate are presented and its limited usefulness is derived. After using methods ESE and EDE we are able to find the inflection point of the cumulative curve under consideration and study its time evolution. Since mortality processes tend to follow a Gompertz distribution, we apply the properties of it and introduce novel estimations for both the time remaining after inflection time and the capacity of the curve. Special properties of sigmoid curves are used for assessing the quality of estimation and as indices for the cycle completion. Application is presented for COVID-19 evolution for most affected countries and the World.{$<$}/p{$>$}},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\VJBTYSA2\\Christopoulos - 2020 - A Novel Approach for Estimating the Final Outcome .pdf:application/pdf},
  journal = {medRxiv},
  language = {en},
  timestamp = {2020-10-28T07:42:42Z}
}

@inproceedings{clarkeSensorActuatorLoop1999,
  title = {Sensor, Actuator and Loop Validation},
  booktitle = {{{IEE Colloquium}} on {{Advances}} in {{Control Technology}} ({{Ref}}. {{No}}. 1999/142),},
  author = {Clarke, D. W.},
  year = {1999},
  month = may,
  pages = {1/1-110},
  doi = {10.1049/ic:19990713},
  abstract = {Economic pressures are dispersing machine intelligence away from centralised computers towards distributed fieldbus devices. Meanwhile the control concept is being extended to include other operational factors such as quality assurance, process data management, just-in-time maintenance, and plant safety and availability. As credible sensing and actuation are essential prerequisites for advanced control, validation of the sensor and actuator interface is necessary. As such subsystems are linked to a range of different overall plant systems, we must consider generic validation and its reporting to the 'next level up'. The paper discusses validation features which are best embedded in local devices.},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\9A82GHHG\\790997.html:text/html},
  timestamp = {2019-08-16T10:30:47Z}
}

@article{corradini_linear_2007,
  title = {Linear Unstable Plants with Saturating Actuators: {{Robust}} Stabilization by a Time Varying Sliding Surface},
  shorttitle = {Linear Unstable Plants with Saturating Actuators},
  author = {Corradini, M. L. and Orlando, G.},
  year = {2007},
  month = jan,
  volume = {43},
  pages = {88--94},
  issn = {0005-1098},
  doi = {10.1016/j.automatica.2006.07.018},
  abstract = {This paper proposes the use of a time-varying sliding surface for the robust stabilization of linear uncertain SISO plants with saturating actuators. A constructive procedure for its design is also proposed, and stability of the closed loop system is proved in the null controllable region. The proposed technique does not require plant stability, and can manage any bounded disturbance term satisfying the matching condition. Theoretical results have been validated by simulation using the missile roll angle control problem.},
  file = {ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\4DJPMCWP\\S0005109806003141.html:text/html},
  journal = {Automatica},
  number = {1},
  timestamp = {2019-05-06T19:47:25Z}
}

@inproceedings{corradini_sliding_2003,
  title = {A Sliding Mode Controller for Actuator Failure Compensation},
  booktitle = {42nd {{IEEE International Conference}} on {{Decision}} and {{Control}} ({{IEEE Cat}}. {{No}}.{{03CH37475}})},
  author = {Corradini, M. L. and Orlando, G.},
  year = {2003},
  month = dec,
  volume = {4},
  pages = {4291-4296 vol.4},
  doi = {10.1109/CDC.2003.1271825},
  abstract = {This paper addresses the actuator failure compensation problem, and considers an uncertain linear plant which is supposed to undergo unknown failures causing the plant input to be stuck at some uncertain but bounded value. Two switching control policies, based on sliding modes, are presented: a state feedback and an output feedback control law. In the former case, a controller guaranteeing the global asymptotical stability of the uncertain system in the presence of failure of unknown pattern and time has been here proposed and discussed. The extension to the output feedback case, shortly addressed for brevity reasons, can be achieved using previous results and introducing and extra switching scheme.},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\TCS7DUUM\\1271825.html:text/html},
  timestamp = {2019-05-06T19:50:46Z}
}

@book{cuyt_handbook_2008,
  title = {Handbook of {{Continued Fractions}} for {{Special Functions}}},
  author = {Cuyt, Annie A. M. and Petersen, Vigdis and Verdonk, Brigitte and Waadeland, Haakon and Jones, William B.},
  year = {2008},
  publisher = {{Springer Netherlands}},
  url = {https://www.springer.com/gb/book/9781402069482},
  urldate = {2019-05-11},
  abstract = {Special functions are pervasive in all fields of science and industry. The most well-known application areas are in physics, engineering, chemistry, computer science and statistics. Because of their importance, several books and websites (see for instance http: functions.wolfram.com) and a large collection of papers have been devoted to these functions. Of the standard work on the subject, namely the Handbook of Mathematical Functions with formulas, graphs and mathematical tables edited by Milton Abramowitz and Irene Stegun, the American National Institute of Standards claims to have sold over 700 000 copies! But so far no project has been devoted to the systematic study of continued fraction representations for these functions. This handbook is the result of such an endeavour. We emphasise that only 10\% of the continued fractions contained in this book, can also be found in the Abramowitz and Stegun project or at the Wolfram website!},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\RQQCEYWC\\9781402069482.html:text/html},
  isbn = {978-1-4020-6948-2},
  language = {en},
  timestamp = {2019-05-11T04:14:58Z}
}

@article{cybenkoApproximationSuperpositionsSigmoidal1989,
  title = {Approximation by Superpositions of a Sigmoidal Function},
  author = {Cybenko, G.},
  year = {1989},
  month = dec,
  volume = {2},
  pages = {303--314},
  issn = {1435-568X},
  doi = {10.1007/BF02551274},
  abstract = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
  journal = {Mathematics of Control, Signals and Systems},
  language = {en},
  number = {4},
  timestamp = {2020-11-09T12:37:39Z}
}

@article{deng_tutorial_2014,
  title = {A Tutorial Survey of Architectures, Algorithms, and Applications for Deep Learning},
  author = {Deng, Li},
  year = {2014/ed},
  volume = {3},
  issn = {2048-7703},
  doi = {10.1017/atsip.2013.9},
  abstract = {In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference [1] are expanded and updated to include more recent developments in deep learning. The previous and the updated materials cover both theory and applications, and analyze its future directions. The goal of this tutorial survey is to introduce the emerging area of deep learning or hierarchical learning to the APSIPA community. Deep learning refers to a class of machine learning techniques, developed largely since 2006, where many stages of non-linear information processing in hierarchical architectures are exploited for pattern classification and for feature learning. In the more recent literature, it is also connected to representation learning, which involves a hierarchy of features or concepts where higher-level concepts are defined from lower-level ones and where the same lower-level concepts help to define higher-level ones. In this tutorial survey, a brief history of deep learning research is discussed first. Then, a classificatory scheme is developed to analyze and summarize major work reported in the recent deep learning literature. Using this scheme, I provide a taxonomy-oriented survey on the existing deep architectures and algorithms in the literature, and categorize them into three classes: generative, discriminative, and hybrid. Three representative deep architectures \textendash{} deep autoencoders, deep stacking networks with their generalization to the temporal domain (recurrent networks), and deep neural networks (pretrained with deep belief networks) \textendash{} one in each of the three classes, are presented in more detail. Next, selected applications of deep learning are reviewed in broad areas of signal and information processing including audio/speech, image/vision, multimodality, language modeling, natural language processing, and information retrieval. Finally, future directions of deep learning are discussed and analyzed.},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\3MVPGH3A\\Deng - 2014 - A tutorial survey of architectures, algorithms, an.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\Y3H8QLLP\\023B6ADF962FA37F8EC684B209E3DFAE.html:text/html},
  journal = {APSIPA Transactions on Signal and Information Processing},
  language = {en},
  timestamp = {2019-05-06T20:08:01Z}
}

@article{ejazSlidingModeControl2017,
  title = {Sliding Mode Control Design of a Ship Steering Autopilot with Input Saturation},
  author = {Ejaz, Muhammad and Chen, Mou},
  year = {2017},
  month = may,
  volume = {14},
  pages = {172988141770356},
  issn = {1729-8814, 1729-8814},
  doi = {10.1177/1729881417703568},
  journal = {International Journal of Advanced Robotic Systems},
  language = {en},
  number = {3},
  timestamp = {2019-07-31T13:18:05Z}
}

@book{elliott_better_1993,
  title = {A Better {{Activation Function}} for {{Artificial Neural Networks}}},
  author = {Elliott, D. L. and Elliott, David L.},
  year = {1993},
  abstract = {An activation function, possibly new, is proposed for use in digital simulation of arti\#cial neural networks, on the ground that the computational operation count for this function is much smaller than for those employing exponentials and it satis\#es a simple di\#erential equation generalizing the logistic equation. Introduction: activation functions  In the digital simulation of neural networks a feedforward memoryless neuron is represented by the input-output relation y = \#\# P  n  1 w k x k \# where \#\#\#\#, the sigmoidal activation or \#squash" function, should have the property that it is positive monotone between the values ,1 and 1 \#or between 0 and 1\# for  u 2 \#,1;1\#. For use in \#nding optimal weights w k to minimize jjy , y desired jj  2  by backpropagation \#gradient\# algorithms, it is also a requirement that \#\#\#\# be di\#erentiable and that it satisfy a simple di\#erential equation, thus permitting the evaluation of increments of weights via the chain rule for partial derivatives. In t...},
  file = {Citeseer - Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\HJU5RSU7\\Elliott and Elliott - 1993 - A better Activation Function for Artificial Neural.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\B2SEKLTL\\summary.html:text/html},
  timestamp = {2019-05-06T20:26:42Z}
}

@incollection{fulwani_design_2013,
  title = {Design of {{Sliding Mode Controller}} with {{Actuator Saturation}}},
  booktitle = {Advances in {{Sliding Mode Control}}: {{Concept}}, {{Theory}} and {{Implementation}}},
  author = {Fulwani, Deepak and Bandyopadhyay, Bijnan},
  editor = {Bandyopadhyay, B. and Janardhanan, S. and Spurgeon, Sarah K.},
  year = {2013},
  pages = {207--219},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-36986-5_10},
  abstract = {This chapter discusses two methods of designing a sliding surface in the face of an actuator saturation constraint for a class of nonlinear uncertain systems. The first approach uses an ARE based approach to design the sliding surface and the second approach uses the parametric Lyapunov equation to design the surface. These methods are based on the low gain approach proposed by Lin et al. The design methods give a surface matrix as a function of the designed parameter. This parameter can be modulated to reduce the control amplitude which ensures that the control limits are respected in a region of the state space. This region can be made sufficiently large by choosing appropriate values of the design parameter.},
  isbn = {978-3-642-36986-5},
  language = {en},
  series = {Lecture {{Notes}} in {{Control}} and {{Information Sciences}}},
  timestamp = {2019-05-06T19:52:27Z}
}

@article{gashlerTrainingDeepFourier2014,
  title = {Training {{Deep Fourier Neural Networks To Fit Time}}-{{Series Data}}},
  author = {Gashler, Michael S. and Ashmore, Stephen C.},
  year = {2014},
  month = may,
  url = {http://arxiv.org/abs/1405.2262},
  urldate = {2020-07-09},
  abstract = {We present a method for training a deep neural network containing sinusoidal activation functions to fit to time-series data. Weights are initialized using a fast Fourier transform, then trained with regularization to improve generalization. A simple dynamic parameter tuning method is employed to adjust both the learning rate and regularization term, such that stability and efficient training are both achieved. We show how deeper layers can be utilized to model the observed sequence using a sparser set of sinusoid units, and how non-uniform regularization can improve generalization by promoting the shifting of weight toward simpler units. The method is demonstrated with time-series problems to show that it leads to effective extrapolation of nonlinear trends.},
  archivePrefix = {arXiv},
  eprint = {1405.2262},
  eprinttype = {arxiv},
  file = {arXiv Fulltext PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\H76VHL5L\\Gashler and Ashmore - 2014 - Training Deep Fourier Neural Networks To Fit Time-.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\RTRJ4TRC\\1405.html:text/html},
  journal = {arXiv:1405.2262 [cs]},
  primaryClass = {cs},
  timestamp = {2020-07-09T07:22:13Z}
}

@article{geirhosShortcutLearningDeep2020,
  title = {Shortcut Learning in Deep Neural Networks},
  author = {Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A.},
  year = {2020},
  month = nov,
  volume = {2},
  pages = {665--673},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-00257-z},
  abstract = {Deep learning has triggered the current rise of artificial intelligence and is the workhorse of today's machine intelligence. Numerous success stories have rapidly spread all over science, industry and society, but its limitations have only recently come into focus. In this Perspective we seek to distil how many of deep learning's failures can be seen as different symptoms of the same underlying problem: shortcut learning. Shortcuts are decision rules that perform well on standard benchmarks but fail to transfer to more challenging testing conditions, such as real-world scenarios. Related issues are known in comparative psychology, education and linguistics, suggesting that shortcut learning may be a common characteristic of learning systems, biological and artificial alike. Based on these observations, we develop a set of recommendations for model interpretation and benchmarking, highlighting recent advances in machine learning to improve robustness and transferability from the lab to real-world applications.},
  copyright = {2020 Springer Nature Limited},
  file = {Submitted Version:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ITQ8UA37\\Geirhos et al. - 2020 - Shortcut learning in deep neural networks.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\6H9G4AC8\\s42256-020-00257-z.html:text/html;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\GA6UDX5N\\s42256-020-00257-z.html:text/html},
  journal = {Nature Machine Intelligence},
  language = {en},
  number = {11},
  timestamp = {2020-12-09T19:50:44Z}
}

@inproceedings{glorotDeepSparseRectifier2011,
  title = {Deep {{Sparse Rectifier Neural Networks}}},
  booktitle = {Proceedings of the {{Fourteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  year = {2011},
  month = jun,
  pages = {315--323},
  publisher = {{JMLR Workshop and Conference Proceedings}},
  issn = {1938-7228},
  url = {http://proceedings.mlr.press/v15/glorot11a.html},
  urldate = {2020-10-20},
  abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neu...},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\TH6R8W5J\\Glorot et al. - 2011 - Deep Sparse Rectifier Neural Networks.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\2SKS62BC\\glorot11a.html:text/html;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\J3UQXE3U\\glorot11a.html:text/html},
  language = {en},
  timestamp = {2020-10-20T10:52:14Z}
}

@book{goldbergDifferentialEquationsSystems1998,
  title = {Differential Equations: A Systems Approach},
  shorttitle = {Differential Equations},
  author = {Goldberg, Jack Leonard and Potter, Merle C.},
  year = {1998},
  publisher = {{Prentice-Hall}},
  abstract = {This book presents the classical theory from a systems point of view, including physical and biological systems. Besides making system theory the unifying take, the book offers an abundance of applications, examples, and problems including many intended for use with MATLAB. Differential Equations with Applications is designed for engineers and scientists. It presents systems of ordinary differential equations and combines classical techniques, applications, and computer solutions. A valuable reference book on differential equations for both engineers and scientists.},
  googlebooks = {nFoZAQAAIAAJ},
  isbn = {978-0-13-211319-9},
  language = {en},
  timestamp = {2019-08-04T17:22:32Z}
}

@book{Goodfellow-et-al-2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {{MIT Press}},
  timestamp = {2020-10-19T09:57:12Z}
}

@inproceedings{goodfellowMaxoutNetworks2013a,
  title = {Maxout Networks},
  booktitle = {International Conference on Machine Learning},
  author = {Goodfellow, Ian and {Warde-Farley}, David and Mirza, Mehdi and Courville, Aaron and Bengio, Yoshua},
  year = {2013},
  pages = {1319--1327},
  publisher = {{PMLR}},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\49FN7KD8\\Goodfellow et al. - 2013 - Maxout networks.pdf:application/pdf},
  timestamp = {2020-09-26T16:20:58Z}
}

@article{greffLSTMSearchSpace2017,
  title = {{{LSTM}}: {{A Search Space Odyssey}}},
  shorttitle = {{{LSTM}}},
  author = {Greff, Klaus and Srivastava, Rupesh K. and Koutn{\'i}k, Jan and Steunebrink, Bas R. and Schmidhuber, J{\"u}rgen},
  year = {2017},
  month = oct,
  volume = {28},
  pages = {2222--2232},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2016.2582924},
  abstract = {Several variants of the long short-term memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful functional ANalysis Of VAriance framework. In total, we summarize the results of 5400 experimental runs ({$\approx$}15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.},
  file = {Submitted Version:C\:\\Users\\SomefunAgba\\Zotero\\storage\\QQCZ4ZFR\\Greff et al. - 2017 - LSTM A Search Space Odyssey.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\P5SKRGU6\\7508408.html:text/html},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  number = {10},
  timestamp = {2020-07-09T08:16:29Z}
}

@article{gTransmissionDynamicsGreat2006,
  title = {Transmission Dynamics of the Great Influenza Pandemic of 1918 in {{Geneva}}, {{Switzerland}}: {{Assessing}} the Effects of Hypothetical Interventions},
  shorttitle = {Transmission Dynamics of the Great Influenza Pandemic of 1918 in {{Geneva}}, {{Switzerland}}},
  author = {G, Chowell and Ce, Ammon and Nw, Hengartner and Jm, Hyman},
  year = {2006},
  month = jul,
  volume = {241},
  publisher = {{J Theor Biol}},
  issn = {0022-5193},
  doi = {10.1016/j.jtbi.2005.11.026},
  abstract = {Recurrent outbreaks of the avian H5N1 influenza virus in Asia represent a constant global pandemic threat. We characterize and evaluate hypothetical public health measures during the 1918 influenza pandemic in the Canton of Geneva, Switzerland. The transmission rate, the recovery rate, the diagnosti \ldots},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\I5WFP8G2\\16387331.html:text/html},
  journal = {Journal of theoretical biology},
  language = {en},
  number = {2},
  pmid = {16387331},
  timestamp = {2020-10-22T10:00:50Z}
}

@article{hahnloserDigitalSelectionAnalogue2000,
  title = {Digital Selection and Analogue Amplification Coexist in a Cortex-Inspired Silicon Circuit},
  author = {Hahnloser, Richard H. R. and Sarpeshkar, Rahul and Mahowald, Misha A. and Douglas, Rodney J. and Seung, H. Sebastian},
  year = {2000},
  month = jun,
  volume = {405},
  pages = {947--951},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/35016072},
  abstract = {Digital circuits such as the flip-flop use feedback to achieve multi-stability and nonlinearity to restore signals to logical levels, for example 0 and 1. Analogue feedback circuits are generally designed to operate linearly, so that signals are over a range, and the response is unique. By contrast, the response of cortical circuits to sensory stimulation can be both multistable and graded1,2,3,4. We propose that the neocortex combines digital selection of an active set of neurons with analogue response by dynamically varying the positive feedback inherent in its recurrent connections. Strong positive feedback causes differential instabilities that drive the selection of a set of active neurons under the constraints embedded in the synaptic weights. Once selected, the active neurons generate weaker, stable feedback that provides analogue amplification of the input. Here we present our model of cortical processing as an electronic circuit that emulates this hybrid operation, and so is able to perform computations that are similar to stimulus selection, gain modulation and spatiotemporal pattern generation in the neocortex.},
  copyright = {2000 Macmillan Magazines Ltd.},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\K9Q2DTR7\\35016072.html:text/html},
  journal = {Nature},
  language = {en},
  number = {6789},
  timestamp = {2020-07-09T06:55:21Z}
}

@inproceedings{hanInfluenceSigmoidFunction1995,
  title = {The Influence of the Sigmoid Function Parameters on the Speed of Backpropagation Learning},
  booktitle = {From {{Natural}} to {{Artificial Neural Computation}}},
  author = {Han, Jun and Moraga, Claudio},
  editor = {Mira, Jos{\'e} and Sandoval, Francisco},
  year = {1995},
  pages = {195--201},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-59497-3_175},
  abstract = {Sigmoid function is the most commonly known function used in feed forward neural networks because of its nonlinearity and the computational simplicity of its derivative. In this paper we discuss a variant sigmoid function with three parameters that denote the dynamic range, symmetry and slope of the function respectively. We illustrate how these parameters influence the speed of backpropagation learning and introduce a hybrid sigmoidal network with different parameter configuration in different layers. By regulating and modifying the sigmoid function parameter configuration in different layers the error signal problem, oscillation problem and asymmetrical input problem can be reduced. To compare the learning capabilities and the learning rate of the hybrid sigmoidal networks with the conventional networks we have tested the two-spirals benchmark that is known to be a very difficult task for backpropagation and their relatives.},
  isbn = {978-3-540-49288-7},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  timestamp = {2020-07-09T07:01:03Z}
}

@article{heDeepResidualLearning2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  month = dec,
  url = {http://arxiv.org/abs/1512.03385},
  urldate = {2020-10-06},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archivePrefix = {arXiv},
  eprint = {1512.03385},
  eprinttype = {arxiv},
  file = {arXiv Fulltext PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\DNSITETI\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\9TZFL8GZ\\1512.html:text/html},
  journal = {arXiv:1512.03385 [cs]},
  primaryClass = {cs},
  timestamp = {2020-10-06T17:23:59Z}
}

@inproceedings{heDelvingDeepRectifiers2015a,
  title = {Delving {{Deep}} into {{Rectifiers}}: {{Surpassing Human}}-{{Level Performance}} on {{ImageNet Classification}}},
  shorttitle = {Delving {{Deep}} into {{Rectifiers}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  month = dec,
  pages = {1026--1034},
  issn = {2380-7504},
  doi = {10.1109/ICCV.2015.123},
  abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94\% top-5 test error on the ImageNet 2012 classification dataset. This is a 26\% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66\% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1\%, [26]) on this dataset.},
  file = {Submitted Version:C\:\\Users\\SomefunAgba\\Zotero\\storage\\7TIDW9RA\\He et al. - 2015 - Delving Deep into Rectifiers Surpassing Human-Lev.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\C8P6946P\\7410480.html:text/html},
  timestamp = {2020-09-26T00:01:01Z}
}

@inproceedings{hemmatiFairEfficientBandwidth2016,
  title = {Fair and Efficient Bandwidth Allocation for Video Flows Using Sigmoidal Programming},
  booktitle = {2016 {{IEEE International Symposium}} on {{Multimedia}} ({{ISM}})},
  author = {Hemmati, Mahdi and McCormick, Bill and Shirmohammadi, Shervin},
  year = {2016},
  pages = {226--231},
  publisher = {{IEEE}},
  timestamp = {2020-11-29T11:39:39Z}
}

@article{hichamSlidingmodeSpeedControl2015,
  title = {Sliding-Mode Speed Control of {{PMSM}} with Fuzzy-Logic Chattering Minimization\textemdash Design and Implementation},
  author = {Hicham, Fadil and Yousfi, Driss and Youness, Aite and Larbi, Elhafyani and Rahim, Nasrudin},
  year = {2015},
  volume = {6},
  pages = {432--442},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\RKFKCLHU\\Hicham et al. - 2015 - Sliding-mode speed control of PMSM with fuzzy-logi.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ICHFT5TY\\432.html:text/html},
  journal = {Information},
  number = {3},
  timestamp = {2019-08-03T04:42:53Z}
}

@article{hochreiterLongShortTermMemory1997,
  title = {Long {{Short}}-{{Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  year = {1997},
  month = nov,
  volume = {9},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\8S6SEH8D\\neco.1997.9.8.html:text/html},
  journal = {Neural Computation},
  number = {8},
  timestamp = {2019-07-29T20:27:08Z}
}

@article{hochreiterUntersuchungenDynamischenNeuronalen1991,
  title = {Untersuchungen Zu Dynamischen Neuronalen {{Netzen}}},
  author = {Hochreiter, Sepp},
  year = {1991},
  volume = {91},
  journal = {Diploma, Technische Universit\"at M\"unchen},
  number = {1},
  timestamp = {2019-07-29T20:25:59Z}
}

@article{hsiehRealtimeForecastMultiphase2006,
  title = {Real-Time {{Forecast}} of {{Multiphase Outbreak}}},
  author = {Hsieh, Ying-Hen and Cheng, Yuan-Sen},
  year = {2006},
  month = jan,
  volume = {12},
  pages = {122--127},
  issn = {1080-6040},
  doi = {10.3201/eid1201.050396},
  abstract = {The multistage Richards model provides insights into ongoing outbreaks that may be useful for real-time public health responses., We used a single equation with discrete phases to fit the daily cumulative case data from the 2003 severe acute respiratory syndrome outbreak in Toronto. This model enabled us to estimate turning points and case numbers during the 2 phases of this outbreak. The 3 estimated turning points are March 25, April 27, and May 24. The estimated case number during the first phase of the outbreak between February 23 and April 26 is 140.53 (95\% confidence interval [CI] 115.88\textendash 165.17) if we use the data from February 23 to April 4; and 249 (95\% CI: 246.67\textendash 251.25) at the end of the second phase on June 12 if we use the data from April 28 to June 4. The second phase can be detected by using case data just 3 days past the beginning of the phase, while the first and third turning points can be identified only {$\approx$}10 days afterwards. Our modeling procedure provides insights into ongoing outbreaks that may facilitate real-time public health responses.},
  file = {PubMed Central Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\K5VGGFJU\\Hsieh and Cheng - 2006 - Real-time Forecast of Multiphase Outbreak.pdf:application/pdf},
  journal = {Emerging Infectious Diseases},
  number = {1},
  pmcid = {PMC3293463},
  pmid = {16494728},
  timestamp = {2020-10-22T00:25:26Z}
}

@incollection{hsiehRichardsModelSimple2009,
  title = {Richards {{Model}}: {{A Simple Procedure}} for {{Real}}-Time {{Prediction}} of {{Outbreak Severity}}},
  shorttitle = {Richards {{Model}}},
  booktitle = {Modeling and {{Dynamics}} of {{Infectious Diseases}}},
  author = {Hsieh, Ying-Hen},
  year = {2009},
  month = apr,
  volume = {Volume 11},
  pages = {216--236},
  publisher = {{CO-PUBLISHED WITH HIGHER EDUCATION PRESS}},
  doi = {10.1142/9789814261265_0009},
  file = {Submitted Version:C\:\\Users\\SomefunAgba\\Zotero\\storage\\UVMW3DDQ\\Hsieh - 2009 - Richards Model A Simple Procedure for Real-time P.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\J6SXSTRD\\9789814261265_0009.html:text/html;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\LM8NS7R3\\9789814261265_0009.html:text/html},
  isbn = {978-981-4261-25-8},
  series = {Series in {{Contemporary Applied Mathematics}}},
  timestamp = {2020-10-19T05:45:47Z}
}

@incollection{isermannActuators2005,
  title = {Actuators},
  booktitle = {Mechatronic {{Systems}}: {{Fundamentals}}},
  editor = {Isermann, Rolf},
  year = {2005},
  pages = {383--486},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/1-84628-259-4_10},
  abstract = {Technical processes are usually influenced or manipulated by actuators, which affect certain input variables. In most cases, electrical, hydraulic or pneumatic auxiliary power is required. The actuator's input variables, the manipulated variables, can be adjusted by feedforward or feedback control or by an operator. Actuators therefore act on the matter or energy flow of the process by means of information processing and are an important link between the signal level of the automation device and the technical process, Figure 10.1.},
  isbn = {978-1-84628-259-1},
  language = {en},
  timestamp = {2019-08-16T10:50:52Z}
}

@article{isermannIntelligentActuatorsWays1993,
  title = {Intelligent Actuators\textemdash{{Ways}} to Autonomous Actuating Systems},
  author = {Isermann, Rolf and Raab, Ulrich},
  year = {1993},
  month = sep,
  volume = {29},
  pages = {1315--1331},
  issn = {0005-1098},
  doi = {10.1016/0005-1098(93)90052-U},
  abstract = {The integration of microelectronics within the actuator allows not only replacement of the analog position controller but addition of several functions which give the actuator more intelligent functions. The actuator control is performed in different levels and includes adaptive nonlinear control, optimization of speed and precision, supervision and fault diagnosis. The actuator knowledge base comprises actuator models based on parameter estimation, controller design and a storage of the learned behavior. An inference mechanism makes decisions for control and fault diagnosis, and a communication module operates internally and externally. After a short review of important actuator principles and their properties, as examples, electromagnetic and pneumatic actuators are considered and it is shown how the control can be improved considerably by model-based nonlinear control, taking into account time varying nonlinear characteristics and hysteresis effects. Supervision with fault detection indicates faults in the electrical and mechanical subsystems of the actuator. Several experimental results are shown including the implementation on a low-cost microcontroller.},
  file = {ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\WTBIZH3H\\000510989390052U.html:text/html},
  journal = {Automatica},
  number = {5},
  timestamp = {2019-08-16T10:29:53Z}
}

@book{isermannMechatronicSystems2003,
  title = {Mechatronic {{Systems}}},
  author = {Isermann, Rolf},
  year = {2003},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/1-84628-259-4},
  isbn = {978-1-85233-930-2 978-1-84628-259-1},
  language = {en},
  timestamp = {2020-07-05T06:01:04Z}
}

@article{isermannMechatronicSystemsInnovative2008,
  title = {Mechatronic Systems\textemdash{{Innovative}} Products with Embedded Control},
  author = {Isermann, Rolf},
  year = {2008},
  month = jan,
  volume = {16},
  pages = {14--29},
  issn = {0967-0661},
  doi = {10.1016/j.conengprac.2007.03.010},
  abstract = {Many technical processes and products in the area of mechanical and electrical engineering are showing an increasing integration of mechanics with digital electronics and information processing. This integration is between the components (hardware) and the information-driven functions (software), resulting in integrated systems called mechatronic systems. Their development involves finding an optimal balance between the basic mechanical structure, sensor and actuator implementation, automatic information processing and overall control. Simultaneous design of mechanics and electronics, hardware and software and embedded control functions resulting in an integrated component or system are all of major importance. This technical progress has a very large influence on a multitude of products in the area of mechanical, electrical and electronic engineering and changes the design, for example, of conventional electromechanical components, machines, vehicles and precision mechanical devices with increasing intensity. This contribution summarizes ongoing developments for mechatronic systems, shows design approaches and examples of mechatronic products and considers various embedded control functions and system's integrity. One field of ongoing developments, automotive mechatronics, where especially large influences can be seen, is described in more detail by discussing mechatronic suspensions, mechatronic brakes, active steering and roll stabilization systems.},
  file = {ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\C7JRQ56X\\S0967066107000603.html:text/html},
  journal = {Control Engineering Practice},
  number = {1},
  timestamp = {2019-08-16T10:46:51Z}
}

@misc{jefferyRestrictedLogarithmicGrowth2016,
  title = {Restricted {{Logarithmic Growth}} with {{Injection}}},
  author = {Jeffery, Phillips Freeman},
  year = {2016},
  month = may,
  url = {http://JeffreyFreeman.me/restricted-logarithmic-growth-with-injection/},
  urldate = {2020-11-30},
  abstract = {The Logistic Function, sometimes with modifications, has been used successfully to model a large range of natural systems. Some examples include...},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\K3JTJY82\\restricted-logarithmic-growth-with-injection.html:text/html},
  journal = {Jeffrey Phillips Freeman},
  timestamp = {2020-11-30T07:19:39Z}
}

@inproceedings{jinDeepLearningSshaped2016,
  title = {Deep Learning with {{S}}-Shaped Rectified Linear Activation Units},
  booktitle = {Proceedings of the {{Thirtieth AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Jin, Xiaojie and Xu, Chunyan and Feng, Jiashi and Wei, Yunchao and Xiong, Junjun and Yan, Shuicheng},
  year = {2016},
  pages = {1737--1743},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\3YEDSYB6\\3016100.html:text/html},
  timestamp = {2020-09-26T16:25:44Z}
}

@book{juditskyStatisticalInferenceConvex2020,
  title = {Statistical Inference via Convex Optimization},
  author = {Juditsky, Anatoli and Nemirovski{\u \i}, Arkadi{\u \i} Semenovich},
  year = {2020},
  publisher = {{Princeton University Press}},
  url = {http://gen.lib.rus.ec/book/index.php?md5=370EFA8CE280E1C4D9F2E4E46D9206B2},
  urldate = {2020-11-29},
  isbn = {978-0-691-19729-6},
  series = {Princeton Series in Applied Mathematics},
  timestamp = {2020-11-29T17:56:34Z}
}

@article{kimErrorReductionSliding2004,
  title = {Error Reduction of Sliding Mode Control Using Sigmoid-Type Nonlinear Interpolation in the Boundary Layer},
  author = {Kim, Yoo-Kyung and Jeon, Gi Joon},
  year = {2004},
  volume = {2},
  pages = {523--529},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\4IWDAGPC\\Kim and Jeon - 2004 - Error reduction of sliding mode control using sigm.pdf:application/pdf},
  journal = {International Journal of Control, Automation, and Systems},
  number = {4},
  timestamp = {2019-08-03T04:48:35Z}
}

@book{kimMATLABDeepLearning2017,
  title = {{{MATLAB Deep Learning}}: {{With Machine Learning}}, {{Neural Networks}} and {{Artificial Intelligence}}},
  author = {Kim, Phil},
  year = {2017},
  publisher = {{Apress}},
  address = {{Berkeley, CA}},
  doi = {10.1007/978-1-4842-2845-6},
  isbn = {978-1-4842-2844-9 978-1-4842-2845-6},
  language = {en},
  timestamp = {2019-08-04T08:42:41Z}
}

@article{klimek_neural_2018,
  title = {Neural {{Network}}-{{Based Approach}} to {{Phase Space Integration}}},
  author = {Klimek, Matthew D. and Perelstein, Maxim},
  year = {2018},
  month = oct,
  url = {http://arxiv.org/abs/1810.11509},
  urldate = {2019-05-11},
  abstract = {Monte Carlo methods are widely used in particle physics to integrate and sample probability distributions (differential cross sections or decay rates) on multi-dimensional phase spaces. We present a Neural Network (NN) algorithm optimized to perform this task. The algorithm has been applied to several examples of direct relevance for particle physics, including situations with non-trivial features such as sharp resonances and soft/collinear enhancements. Excellent performance has been demonstrated in all examples, with the properly trained NN achieving unweighting efficiencies of between 30\% and 75\%. In contrast to traditional Monte Carlo algorithms such as VEGAS, the NN-based approach does not require that the phase space coordinates be aligned with resonant or other features in the cross section.},
  archivePrefix = {arXiv},
  eprint = {1810.11509},
  eprinttype = {arxiv},
  file = {arXiv\:1810.11509 PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\J53VGAX2\\Klimek and Perelstein - 2018 - Neural Network-Based Approach to Phase Space Integ.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\2PXTTTKN\\1810.html:text/html},
  journal = {arXiv:1810.11509 [hep-ex, physics:hep-ph, physics:physics, stat]},
  primaryClass = {hep-ex, physics:hep-ph, physics:physics, stat},
  timestamp = {2019-05-11T02:58:12Z}
}

@inproceedings{kongHexpoVanishingproofActivation2017,
  title = {Hexpo: {{A}} Vanishing-Proof Activation Function},
  shorttitle = {Hexpo},
  booktitle = {2017 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Kong, Shumin and Takatsuka, Masahiro},
  year = {2017},
  month = may,
  pages = {2562--2567},
  publisher = {{IEEE}},
  address = {{Anchorage, AK, USA}},
  doi = {10.1109/IJCNN.2017.7966168},
  isbn = {978-1-5090-6182-2},
  timestamp = {2019-07-29T18:37:56Z}
}

@incollection{lecunEfficientBackProp1998,
  title = {Efficient {{BackProp}}},
  booktitle = {Neural {{Networks}}: {{Tricks}} of the {{Trade}}},
  author = {LeCun, Yann and Bottou, Leon and Orr, Genevieve B. and M{\"u}ller, Klaus -Robert},
  editor = {Orr, Genevieve B. and M{\"u}ller, Klaus-Robert},
  year = {1998},
  pages = {9--50},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-49430-8_2},
  abstract = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observedb y practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposedin serious technical publications. This paper gives some of those tricks, ando.ers explanations of why they work. Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most ``classical'' second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.},
  file = {Springer Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\RNUDD7QK\\LeCun et al. - 1998 - Efficient BackProp.pdf:application/pdf},
  isbn = {978-3-540-49430-0},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  timestamp = {2019-07-29T18:38:34Z}
}

@article{leeEstimationCOVID19Spread2020,
  title = {Estimation of {{COVID}}-19 Spread Curves Integrating Global Data and Borrowing Information},
  author = {Lee, Se Yoon and Lei, Bowen and Mallick, Bani},
  year = {2020},
  month = jul,
  volume = {15},
  pages = {e0236860},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0236860},
  abstract = {Currently, novel coronavirus disease 2019 (COVID-19) is a big threat to global health. The rapid spread of the virus has created pandemic, and countries all over the world are struggling with a surge in COVID-19 infected cases. There are no drugs or other therapeutics approved by the US Food and Drug Administration to prevent or treat COVID-19: information on the disease is very limited and scattered even if it exists. This motivates the use of data integration, combining data from diverse sources and eliciting useful information with a unified view of them. In this paper, we propose a Bayesian hierarchical model that integrates global data for real-time prediction of infection trajectory for multiple countries. Because the proposed model takes advantage of borrowing information across multiple countries, it outperforms an existing individual country-based model. As fully Bayesian way has been adopted, the model provides a powerful predictive tool endowed with uncertainty quantification. Additionally, a joint variable selection technique has been integrated into the proposed modeling scheme, which aimed to identify possible country-level risk factors for severe disease due to COVID-19.},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\3BHX2YUK\\Lee et al. - 2020 - Estimation of COVID-19 spread curves integrating g.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\IJWUSUFP\\article.html:text/html},
  journal = {PLOS ONE},
  language = {en},
  number = {7},
  timestamp = {2020-11-29T05:55:08Z}
}

@article{lipovetsky_double_2010,
  title = {Double Logistic Curve in Regression Modeling},
  author = {Lipovetsky, Stan},
  year = {2010},
  month = nov,
  volume = {37},
  pages = {1785--1793},
  issn = {0266-4763},
  doi = {10.1080/02664760903093633},
  abstract = {The logistic sigmoid curve is widely used in nonlinear regression and in binary response modeling. There are problems corresponding to a double sigmoid behavior which consists of the first increase to an early saturation at an intermediate level, and the second sigmoid with the eventual plateau of saturation. A double sigmoid behavior is usually achieved using additive or multiplicative combinations of logit and more complicated functions with numerous parameters. In this work, double sigmoid functions are constructed as logistic ones with a sign defining the point of inflection and with an additional powering parameter. The elaborated models describe rather complicated double saturation behavior via only four or five parameters which can be efficiently estimated by nonlinear optimization techniques. Theoretical features and practical applications of the models are discussed.},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\DYV9V3EF\\02664760903093633.html:text/html},
  journal = {Journal of Applied Statistics},
  number = {11},
  timestamp = {2019-05-06T20:13:12Z}
}

@article{loibelInferenceRichardsGrowth2006,
  title = {Inference for the {{Richards}} Growth Model Using {{Box}} and {{Cox}} Transformation and Bootstrap Techniques},
  author = {Loibel, Selene and {do Val}, Jo{\~a}o B. R. and Andrade, Marinho G.},
  year = {2006},
  month = feb,
  volume = {191},
  pages = {501--512},
  issn = {0304-3800},
  doi = {10.1016/j.ecolmodel.2005.05.024},
  abstract = {The paper considers the parameter identification of the Richards population growth model, a class of models that generalizes the logistic and the Gompertz growth model classes. The use of the Richards class presents an identifiability problem that is worsened when handling small data samples, a situation often encountered in animal population modeling. This paper tackles the identifiability problem by regarding the growth rate form parameter (q) in the Richards' model as the parameter in the corresponding Box\textendash Cox data transformation, leading to a model that can be interpreted as a logistic growth model. In order to assure better interval estimation for the model parameters, the approach is complemented with the profile maximum likelihood estimates of the q parameter of the Richards model combined with the bootstrap technique. Some tests using generated and measured data are presented to illustrate the technique.},
  file = {ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\BI5QI8DD\\S0304380005002814.html:text/html},
  journal = {Ecological Modelling},
  language = {en},
  number = {3},
  timestamp = {2020-11-29T15:03:50Z}
}

@inproceedings{maasRectifierNonlinearitiesImprove2013a,
  title = {Rectifier Nonlinearities Improve Neural Network Acoustic Models},
  booktitle = {Proc. Icml},
  author = {Maas, Andrew L. and Hannun, Awni Y. and Ng, Andrew Y.},
  year = {2013},
  volume = {30},
  pages = {3},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\E8HZ6P7P\\Maas et al. - 2013 - Rectifier nonlinearities improve neural network ac.pdf:application/pdf},
  timestamp = {2020-10-20T11:19:53Z}
}

@article{mansor_performance_2016,
  title = {Performance Analysis of Activation Function in Higher Order Logic Programming},
  author = {Mansor, Mohd. Asyraf and Sathasivam, Saratha},
  year = {2016},
  month = jun,
  volume = {1750},
  pages = {030007},
  issn = {0094-243X},
  doi = {10.1063/1.4954543},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\YH38PIPN\\Mansor and Sathasivam - 2016 - Performance analysis of activation function in hig.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\BIWG9NHV\\1.html:text/html},
  journal = {AIP Conference Proceedings},
  number = {1},
  timestamp = {2019-05-06T19:43:28Z}
}

@misc{matthewWhyModelingSpread2020,
  title = {Why {{Modeling}} the {{Spread}} of {{COVID}}-19 {{Is So Damn Hard}} - {{IEEE Spectrum}}},
  author = {Matthew, Hutson},
  year = {2020},
  month = sep,
  url = {https://spectrum.ieee.org/artificial-intelligence/medical-ai/why-modeling-the-spread-of-covid19-is-so-damn-hard},
  urldate = {2020-12-04},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\PU7622RS\\why-modeling-the-spread-of-covid19-is-so-damn-hard.html:text/html},
  journal = {IEEE Spectrum: Technology, Engineering, and Science News},
  language = {en},
  timestamp = {2020-12-05T15:26:22Z}
}

@article{mcdowall_calculation_2006,
  title = {Calculation of Threshold and Saturation Points of Sigmoidal Baroreflex Function Curves},
  author = {McDowall, Lachlan M. and Dampney, Roger A. L.},
  year = {2006},
  month = oct,
  volume = {291},
  pages = {H2003-H2007},
  issn = {0363-6135},
  doi = {10.1152/ajpheart.00219.2006},
  abstract = {The logistic sigmoid function curve provides an accurate description of the baroreflex input-output relationship and is the most commonly used equation for this purpose. The threshold (Thr) and saturation (Sat) values for the baroreflex are commonly defined as the values of mean arterial pressure (MAP) at which the reflexly controlled variable (e.g., heart rate or sympathetic nerve activity) is within 5\% of the upper or lower plateau, respectively, of the sigmoid function. These values are referred to here as Thr5\% and Sat5\%. In many studies, Thr and Sat are calculated with the equations Thr = A3 - 2.0/A2 and Sat = A3 + 2.0/A2, where A3 is the value of MAP at the point where the reflexly controlled variable is at the midpoint of its range and A2 is the gain coefficient. Although it is commonly stated that the values of Thr and Sat calculated with these equations represent Thr5\% and Sat5\%, we show here that instead they are significantly greater and less than Thr5\% and Sat5\%, respectively. Furthermore, the operating range (difference between Thr and Sat) calculated with these equations is 32\% less than the difference between Thr5\% and Sat5\%. We further show that the equations that provide correct values of Thr5\% and Sat5\% are Thr5\% = A3 - 2.944/A2 and Sat5\% = A3 + 2.944/A2. We propose that these be used as the standard equations for calculating threshold and saturation values when a logistic sigmoid function is used to model the open-loop baroreflex function curve.},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\V8V99LTD\\McDowall and Dampney - 2006 - Calculation of threshold and saturation points of .pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ZSRVTA8A\\ajpheart.00219.html:text/html},
  journal = {American Journal of Physiology-Heart and Circulatory Physiology},
  number = {4},
  timestamp = {2019-05-06T20:11:56Z}
}

@article{mohammadComparisonArtificialNeural2012,
  title = {Comparison of Artificial Neural Network Transfer Functions Abilities to Simulate Extreme Runoff Data.},
  author = {Mohammad, Dorofki and Elshafie, A. H. and Othman, Jaafar and Karim, O. A. and Sharifah, Mastura},
  year = {2012},
  volume = {33},
  pages = {39--44},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\HQXYTMVI\\www.cabdirect.org.html:text/html},
  journal = {International Proceedings of Chemical, Biological and Environmental Engineering (IPCBEE)},
  timestamp = {2019-07-29T20:49:50Z}
}

@inproceedings{mostafaApproximationActivationFunctions2014,
  title = {Approximation of Activation Functions for Vector Equalization Based on Recurrent Neural Networks},
  booktitle = {2014 8th {{International Symposium}} on {{Turbo Codes}} and {{Iterative Information Processing}} ({{ISTC}})},
  author = {Mostafa, Mohamad and Teich, Werner G. and Lindner, J{\"u}rgen},
  year = {2014},
  month = aug,
  pages = {52--56},
  issn = {2165-4719},
  doi = {10.1109/ISTC.2014.6955084},
  abstract = {Activation functions represent an essential element in all neural networks structures. They influence the overall behavior of neural networks decisively because of their nonlinear characteristic. Discrete- and continuous-time recurrent neural networks are a special class of neural networks. They have been shown to be able to perform vector equalization without the need for a training phase because they are Lyapunov stable under specific conditions. The activation function in this case depends on the symbol alphabet and is computationally complex to be evaluated. In addition, numerical instability can occur during the evaluation. Thus, there is a need for a computationally less complex and numerically stable evaluation. Especially for the continuous-time recurrent neural network, the evaluation must be suitable for an analog implementation. In this paper, we introduce an approximation of the activation function for vector equalization with recurrent neural networks. The activation function is approximated as a sum of shifted hyperbolic tangent functions, which can easily be realized in analog by a differential amplifier. Based on our ongoing research in this field, the analog implementation of vector equalization with recurrent neural networks is expected to improve the power/speed ratio by several order of magnitude compared with the digital one.},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\E6LYX6ZQ\\references.html:text/html},
  timestamp = {2020-07-06T22:05:02Z}
}

@article{mostafaLocalStabilityAnalysis2014,
  title = {Local Stability Analysis of Discrete-Time, Continuous-State, Complex-Valued Recurrent Neural Networks with Inner State Feedback},
  author = {Mostafa, M. and Teich, W. G. and Lindner, J.},
  year = {2014},
  volume = {25},
  pages = {830--836},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  number = {4},
  timestamp = {2020-07-07T12:12:58Z}
}

@book{mullerElementaryFunctionsAlgorithms2016,
  title = {Elementary {{Functions}}: {{Algorithms}} and {{Implementation}}},
  shorttitle = {Elementary {{Functions}}},
  author = {Muller, Jean-Michel},
  year = {2016},
  edition = {Third},
  publisher = {{Birkh\"auser Basel}},
  doi = {10.1007/978-1-4899-7983-4},
  abstract = {This textbook presents the concepts and tools necessary to understand, build, and implement algorithms for computing elementary functions (e.g., logarithms, exponentials, and the trigonometric functions). Both hardware- and software-oriented algorithms are included, along with issues related to accurate floating-point implementation. This third edition has been updated and expanded to incorporate the most recent advances in the field, new elementary function algorithms, and function software.After a preliminary chapter that briefly introduces some fundamental concepts of computer arithmetic, such as floating-point arithmetic and redundant number systems, the text is divided into three main parts. Part I considers the computation of elementary functions using algorithms based on polynomial or rational approximations and using table-based methods; the final chapter in this section deals with basic principles of multiple-precision arithmetic. Part II is devoted to a presentation of ``shift-and-add'' algorithms (hardware-oriented algorithms that use additions and shifts only). Issues related to accuracy, including range reduction, preservation of monotonicity, and correct rounding, as well as some examples of implementation are explored in Part III. Numerous examples of command lines and full programs are provided throughout for various software packages, including Maple, Sollya, and Gappa. New to this edition are an in-depth overview of the IEEE-754-2008 standard for floating-point arithmetic; a section on using double- and triple-word numbers; a presentation of new tools for designing accurate function software; and a section on the Toom-Cook family of multiplication algorithms.The techniques presented in this book will be of interest to implementers of elementary function libraries or circuits and programmers of numerical applications. Additionally, graduate and advanced undergraduate students, professionals, and researchers in scientific computing, numerical analysis, software engineering, and computer engineering will find this a useful reference and resource.PRAISE FOR PREVIOUS EDITIONS``[T]his book seems like an essential reference for the experts (which I'm not). More importantly, this is an interesting book for the curious (which I am). In this case, you'll probably learn many interesting things from this book. If you teach numerical analysis or approximation theory, then this book will give you some good examples to discuss in class." \textemdash{} MAA Reviews (Review of Second Edition)"The rich content of ideas sketched or presented in some detail in this book is supplemented by a list of over three hundred references, most of them of 1980 or more recent. The book also contains some relevant typical programs." \textemdash{} Zentralblatt MATH (Review of Second Edition)``I think that the book will be very valuable to students both in numerical analysis and in computer science. I found [it to be] well written and containing much interesting material, most of the time disseminated in specialized papers published in specialized journals difficult to find." \textemdash{} Numerical Algorithms (Review of First Edition)},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\6SBR7FKS\\9781489979810.html:text/html},
  isbn = {978-1-4899-7981-0},
  language = {en},
  timestamp = {2020-07-06T05:07:40Z}
}

@article{mullerElementaryFunctionsApproximate2020,
  title = {Elementary {{Functions}} and {{Approximate Computing}}},
  author = {Muller, Jean-Michel},
  year = {2020},
  pages = {1--14},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2020.2991885},
  abstract = {In this article, we review some of the classical methods used for quickly obtaining low-precision approximations to the elementary functions. Then, for each of the three main classes of elementary function algorithms (shift-and-add algorithms, polynomial or rational approximations, and table-based methods) and for the additional, specific to approximate computing, ``bit-manipulation'' techniques, we examine what can be done for obtaining very fast estimates of a function, at the cost of a (controlled) loss in terms of accuracy.},
  journal = {Proceedings of the IEEE},
  timestamp = {2020-07-06T05:04:30Z}
}

@inproceedings{nairRectifiedLinearUnits2010,
  title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{International Conference}} on {{Machine Learning}}},
  author = {Nair, Vinod and Hinton, Geoffrey E.},
  year = {2010},
  month = jun,
  pages = {807--814},
  publisher = {{Omnipress}},
  address = {{Madison, WI, USA}},
  abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these "Stepped Sigmoid Units" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
  isbn = {978-1-60558-907-7},
  series = {{{ICML}}'10},
  timestamp = {2020-10-20T10:51:32Z}
}

@article{nwankpaActivationFunctionsComparison2018,
  title = {Activation {{Functions}}: {{Comparison}} of Trends in {{Practice}} and {{Research}} for {{Deep Learning}}},
  shorttitle = {Activation {{Functions}}},
  author = {Nwankpa, Chigozie and Ijomah, Winifred and Gachagan, Anthony and Marshall, Stephen},
  year = {2018},
  month = nov,
  url = {http://arxiv.org/abs/1811.03378},
  urldate = {2019-07-29},
  abstract = {Deep neural networks have been successfully used in diverse emerging domains to solve real world complex problems with may more deep learning(DL) architectures, being developed to date. To achieve these state-of-the-art performances, the DL architectures use activation functions (AFs), to perform diverse computations between the hidden layers and the output layers of any given DL architecture. This paper presents a survey on the existing AFs used in deep learning applications and highlights the recent trends in the use of the activation functions for deep learning applications. The novelty of this paper is that it compiles majority of the AFs used in DL and outlines the current trends in the applications and usage of these functions in practical deep learning deployments against the state-of-the-art research results. This compilation will aid in making effective decisions in the choice of the most suitable and appropriate activation function for any given application, ready for deployment. This paper is timely because most research papers on AF highlights similar works and results while this paper will be the first, to compile the trends in AF applications in practice against the research results from literature, found in deep learning research to date.},
  archivePrefix = {arXiv},
  eprint = {1811.03378},
  eprinttype = {arxiv},
  file = {arXiv\:1811.03378 PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\QZVCEIPL\\Nwankpa et al. - 2018 - Activation Functions Comparison of trends in Prac.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\P386YL4W\\1811.html:text/html},
  journal = {arXiv:1811.03378 [cs]},
  primaryClass = {cs},
  timestamp = {2019-07-29T20:18:02Z}
}

@article{ohnSmoothFunctionApproximation2019,
  title = {Smooth {{Function Approximation}} by {{Deep Neural Networks}} with {{General Activation Functions}}},
  author = {Ohn, Ilsang and Kim, Yongdai},
  year = {2019},
  month = jul,
  volume = {21},
  pages = {627},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/e21070627},
  abstract = {There has been a growing interest in expressivity of deep neural networks. However, most of the existing work about this topic focuses only on the specific activation function such as ReLU or sigmoid. In this paper, we investigate the approximation ability of deep neural networks with a broad class of activation functions. This class of activation functions includes most of frequently used activation functions. We derive the required depth, width and sparsity of a deep neural network to approximate any H\&ouml;lder smooth function upto a given approximation error for the large class of activation functions. Based on our approximation error analysis, we derive the minimax optimality of the deep neural network estimators with the general activation functions in both regression and classification problems.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\WIQME7Q7\\Ohn and Kim - 2019 - Smooth Function Approximation by Deep Neural Netwo.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\D8E48835\\627.html:text/html},
  journal = {Entropy},
  language = {en},
  number = {7},
  timestamp = {2020-07-06T22:12:25Z}
}

@article{okabeMathematicalModelEpidemics2020,
  title = {A {{Mathematical Model}} of {{Epidemics}}---{{A Tutorial}} for {{Students}}},
  author = {Okabe, Yutaka and Shudo, Akira},
  year = {2020},
  month = jul,
  volume = {8},
  pages = {1174},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/math8071174},
  abstract = {This is a tutorial for the mathematical model of the spread of epidemic diseases. Beginning with the basic mathematics, we introduce the susceptible-infected-recovered (SIR) model. Subsequently, we present the numerical and exact analytical solutions of the SIR model. The analytical solution is emphasized. Additionally, we treat the generalization of the SIR model including births and natural deaths.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\2YY2HKYL\\Okabe and Shudo - 2020 - A Mathematical Model of Epidemics—A Tutorial for S.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\SVIBANK5\\htm.html:text/html},
  journal = {Mathematics},
  language = {en},
  number = {7},
  timestamp = {2020-10-20T09:49:39Z}
}

@book{omidvarNeuralSystemsControl1997,
  title = {Neural {{Systems}} for {{Control}}},
  author = {Omidvar, Omid and Elliott, David L.},
  year = {1997},
  edition = {1st},
  publisher = {{Academic Press}},
  isbn = {978-0-12-526430-3},
  timestamp = {2020-09-26T05:22:24Z}
}

@article{paraliArtificialNeuralNetwork2017,
  title = {The Artificial Neural Network Modelling of the Piezoelectric Actuator Vibrations Using Laser Displacement Sensor},
  author = {Paral{\i}, Levent and Sar{\i}, Ali and K{\i}l{\i}{\c c}, Ula{\c s} and {\c S}ahin, {\"O}zge and P{\v e}chou{\v s}ek, Ji{\v r}{\'i}},
  year = {2017},
  month = sep,
  volume = {68},
  pages = {371--377},
  doi = {10.1515/jee-2017-0069},
  journal = {Journal of Electrical Engineering},
  language = {en},
  number = {5},
  timestamp = {2019-07-30T06:59:27Z}
}

@article{pernaIndividualRulesTrail2012,
  title = {Individual {{Rules}} for {{Trail Pattern Formation}} in {{Argentine Ants}} ({{Linepithema}} Humile)},
  author = {Perna, Andrea and Granovskiy, Boris and Garnier, Simon and Nicolis, Stamatios C. and Lab{\'e}dan, Marjorie and Theraulaz, Guy and Fourcassi{\'e}, Vincent and Sumpter, David J. T.},
  year = {2012},
  month = jul,
  volume = {8},
  pages = {e1002592},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1002592},
  abstract = {We studied the formation of trail patterns by Argentine ants exploring an empty arena. Using a novel imaging and analysis technique we estimated pheromone concentrations at all spatial positions in the experimental arena and at different times. Then we derived the response function of individual ants to pheromone concentrations by looking at correlations between concentrations and changes in speed or direction of the ants. Ants were found to turn in response to local pheromone concentrations, while their speed was largely unaffected by these concentrations. Ants did not integrate pheromone concentrations over time, with the concentration of pheromone in a 1 cm radius in front of the ant determining the turning angle. The response to pheromone was found to follow a Weber's Law, such that the difference between quantities of pheromone on the two sides of the ant divided by their sum determines the magnitude of the turning angle. This proportional response is in apparent contradiction with the well-established non-linear choice function used in the literature to model the results of binary bridge experiments in ant colonies (Deneubourg et al. 1990). However, agent based simulations implementing the Weber's Law response function led to the formation of trails and reproduced results reported in the literature. We show analytically that a sigmoidal response, analogous to that in the classical Deneubourg model for collective decision making, can be derived from the individual Weber-type response to pheromone concentrations that we have established in our experiments when directional noise around the preferred direction of movement of the ants is assumed.},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ZGHSK2BB\\Perna et al. - 2012 - Individual Rules for Trail Pattern Formation in Ar.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\BRQUDXHN\\article.html:text/html},
  journal = {PLOS Computational Biology},
  language = {en},
  number = {7},
  timestamp = {2020-07-10T04:25:32Z}
}

@article{peterParameterAdaptiveControlBased1990,
  title = {Parameter-{{Adaptive Control Based}} on {{Continuous}}-{{Time Process Models}}},
  author = {Peter, K. and Isermann, R.},
  year = {1990},
  month = aug,
  volume = {23},
  pages = {443--448},
  issn = {1474-6670},
  doi = {10.1016/S1474-6670(17)52049-2},
  abstract = {The paper is concerned with a hybrid approach to parameter-adaptive control schemes using continuous-time process descriptions but discrete-time control laws and parameter estimation procedures. The process model described by an ordinary differential equation is identified by means of the well-known state variable filter method. An improved digital state variable filter is presented which allows to generate the state variables of the process signals almost perfectly even in case the filter is operat i ng with a slow sampling rate, Particular emphasis is laid on the design of optimal PID-controllers by minimization of quadratic cost functions. A controller tuning mechanism is introduced which approximates the optimal solution for a specific class of processes . This tuning mechanism is very fast and quite easy to implement on a micro-computer with limited computational capabili ties. The efficiency of the hybrid parameter-adaptive PID-controller is demonstrated by means of some simulation results.},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ENZIBDPQ\\Peter and Isermann - 1990 - Parameter-Adaptive Control Based on Continuous-Tim.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\K2YMGTEE\\S1474667017520492.html:text/html},
  journal = {IFAC Proceedings Volumes},
  number = {8, Part 2},
  series = {11th {{IFAC World Congress}} on {{Automatic Control}}, {{Tallinn}}, 1990 - {{Volume}} 2, {{Tallinn}}, {{Finland}}},
  timestamp = {2019-08-22T20:13:24Z}
}

@book{peypouquetConvexOptimizationNormed2015,
  title = {Convex {{Optimization}} in {{Normed Spaces}}: {{Theory}}, {{Methods}} and {{Examples}}},
  shorttitle = {Convex {{Optimization}} in {{Normed Spaces}}},
  author = {Peypouquet, Juan},
  year = {2015},
  publisher = {{Springer}},
  url = {http://gen.lib.rus.ec/book/index.php?md5=068a220d892d53a35dddb3d3a7ed15ed},
  urldate = {2020-11-29},
  isbn = {978-3-319-13709-4},
  series = {{{SpringerBriefs}} in {{Optimization}}},
  timestamp = {2020-11-29T17:52:14Z}
}

@article{pfeuferIntelligentElectromechanicalServosystem1996,
  title = {Intelligent {{Electromechanical Servosystem}}},
  author = {Pfeufer, Thomas and Isermann, Rolf},
  year = {1996},
  month = jun,
  volume = {29},
  pages = {7272--7277},
  issn = {1474-6670},
  doi = {10.1016/S1474-6670(17)58855-2},
  abstract = {Servo systems play an important role in many automated processes. In order to fulfil the hard demands on reliability and fast and precise operation, intelligent concepts for the control, supervision and (reconfiguration are necessary. In this paper, an approach is presented which integrates different levels of signal processing in an electromechanical servo system. The digital controller and the model-based fault detection scheme are designed taking into account model-uncertainty and the time variant process behaviour, which is caused by temperature influences. After a brief description of the theoretical basis an experimental application shows results for an automobile servo system which is driven by a d.c. motor.},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\S8N336JA\\Pfeufer and Isermann - 1996 - Intelligent Electromechanical Servosystem.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\HXQJVDXN\\S1474667017588552.html:text/html},
  journal = {IFAC Proceedings Volumes},
  number = {1},
  series = {13th {{World Congress}} of {{IFAC}}, 1996, {{San Francisco USA}}, 30 {{June}} - 5 {{July}}},
  timestamp = {2019-08-16T10:47:45Z}
}

@techreport{pinedadegyvezHardwareImplementationDesktop1994,
  title = {Hardware {{Implementation}} of a {{Desktop Supercomputer}} for {{High Performance Image Processing}}. {{Time Multiplexed Color Image Processing Based}} on a {{VLSI Cellular Neural Network}} with {{Cell}}-{{State Outputs}}},
  author = {{Pineda de Gyvez}, Jose},
  year = {1994},
  institution = {{Texas A and M University College Station Dept Of Electrical Engineering}},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\CE5RAYXV\\Pineda de Gyvez - 1994 - Hardware Implementation of a Desktop Supercomputer.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\BRQZ7XDH\\ADA280550.html:text/html},
  timestamp = {2020-07-05T17:47:15Z},
  type = {Technical}
}

@book{polkingOrdinaryDifferentialEquations1999,
  title = {Ordinary Differential Equations Using {{MATLAB}}},
  author = {Polking, John C. and Arnold, David},
  year = {1999},
  month = jun,
  publisher = {{Prentice Hall}},
  googlebooks = {YVgZAQAAIAAJ},
  language = {en},
  timestamp = {2019-08-04T17:23:01Z}
}

@book{prywerBiologicalBiogenicCrystallization2019,
  title = {Biological and {{Biogenic Crystallization}}},
  author = {Prywer, Jolanta},
  year = {2019},
  month = mar,
  publisher = {{MDPI}},
  abstract = {The intention of the Special Issue \&quot;Biological and Biogenic Crystallization\&quot; was to create an international platform aimed at covering a broad field of results involving the crystallization of biological molecules, including virus and protein crystallization, biogenic crystallization including physiological and pathological crystallization taking place in living organisms (human beings, animals, plants, bacteria, etc.), and bio-inspired crystallization. Despite many years of research on biological and biogenic crystals, there are still open questions as well as hot and timely topics. This Special Issue contains seven articles that present a cross-section of the current research activities in the of field of biological and biogenic crystals. The authors of the presented articles prove the vibrant and topical nature of this field. We hope that this Special Issue will serve as a source of inspiration for future investigations, and will be useful for scientists and researchers who work on the exploration of biological and biogenic crystals.},
  googlebooks = {EluNDwAAQBAJ},
  isbn = {978-3-03897-521-2},
  language = {en},
  timestamp = {2019-08-04T17:20:31Z}
}

@misc{quModifiedSineCosineAlgorithm2018a,
  title = {A {{Modified Sine}}-{{Cosine Algorithm Based}} on {{Neighborhood Search}} and {{Greedy Levy Mutation}}},
  author = {Qu, Chiwen and Zeng, Zhiliu and Dai, Jun and Yi, Zhongjun and He, Wei},
  year = {2018},
  doi = {10.1155/2018/4231647},
  abstract = {For the deficiency of the basic sine-cosine algorithm in dealing with global optimization problems such as the low solution precision and the slow convergence speed, a new improved sine-cosine algorithm is proposed in this paper. The improvement involves three optimization strategies. Firstly, the method of exponential decreasing conversion parameter and linear decreasing inertia weight is adopted to balance the global exploration and local development ability of the algorithm. Secondly, it uses the random individuals near the optimal individuals to replace the optimal individuals in the primary algorithm, which allows the algorithm to easily jump out of the local optimum and increases the search range effectively. Finally, the greedy Levy mutation strategy is used for the optimal individuals to enhance the local development ability of the algorithm. The experimental results show that the proposed algorithm can effectively avoid falling into the local optimum, and it has faster convergence speed and higher optimization accuracy.},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\P27BPW5Q\\4231647.html:application/xhtml+xml;Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\R8HFSJLR\\Qu et al. - 2018 - A Modified Sine-Cosine Algorithm Based on Neighbor.pdf:application/pdf},
  journal = {Computational Intelligence and Neuroscience},
  language = {en},
  timestamp = {2019-08-17T04:37:52Z},
  type = {Research Article}
}

@article{rairanRobotPathOptimization2015,
  title = {Robot {{Path Optimization Based}} on a {{Reference Model}} and {{Sigmoid Functions}}},
  author = {Rairan, Jose Danilo},
  year = {2015},
  month = mar,
  volume = {12},
  pages = {19},
  publisher = {{SAGE Publications}},
  issn = {1729-8814},
  doi = {10.5772/60063},
  abstract = {The purpose of this study is to minimize the arc length for the path described by the model of a robot platform when the path is constrained to have smooth transitions given by sigmoid functions. The optimization required a proof of stability for the resulting control law, the selection of the best sigmoid function among ten functions, and the definition of two gains necessary to parameterize the control law. The optimization was carried out by simulating the system under several kinematic and dynamical conditions, and the best sigmoid function was a hyperbolic tangent. Thus, the motion control first implied the simulation of a reference model to define an optimal path, and later the control of an actual robot platform, which followed the optimal path. The use of the optimized path reduced the complexity of the controller while allowing natural and intuitive paths for the robot platform.},
  file = {SAGE PDF Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\TM2H6AWM\\Rairan - 2015 - Robot Path Optimization Based on a Reference Model.pdf:application/pdf},
  journal = {International Journal of Advanced Robotic Systems},
  language = {en},
  number = {3},
  timestamp = {2020-07-10T04:25:43Z}
}

@article{reedSummationLogisticCurves1927,
  title = {On the {{Summation}} of {{Logistic Curves}}},
  author = {Reed, Lowell J. and Pearl, Raymond},
  year = {1927},
  volume = {90},
  pages = {729--746},
  publisher = {{[Wiley, Royal Statistical Society]}},
  issn = {0952-8385},
  doi = {10.2307/2341367},
  journal = {Journal of the Royal Statistical Society},
  number = {4},
  timestamp = {2020-10-22T13:04:24Z}
}

@article{roodschildNewApproachVanishing2020,
  title = {A New Approach for the Vanishing Gradient Problem on Sigmoid Activation},
  author = {Roodschild, Mat{\'i}as and Gotay Sardi{\~n}as, Jorge and Will, Adri{\'a}n},
  year = {2020},
  month = dec,
  volume = {9},
  pages = {351--360},
  issn = {2192-6352, 2192-6360},
  doi = {10.1007/s13748-020-00218-y},
  journal = {Progress in Artificial Intelligence},
  language = {en},
  number = {4},
  timestamp = {2020-12-14T05:15:01Z}
}

@article{roserCoronavirusPandemicCOVID192020,
  title = {Coronavirus {{Pandemic}} ({{COVID}}-19)},
  author = {Roser, Max and Ritchie, Hannah and {Ortiz-Ospina}, Esteban and Hasell, Joe},
  year = {2020},
  month = may,
  url = {https://ourworldindata.org/coronavirus/country/nigeria},
  urldate = {2020-10-19},
  abstract = {Nigeria: What has been the impact of the Coronavirus Pandemic (COVID-19)?},
  journal = {Our World in Data},
  timestamp = {2020-10-19T08:12:14Z}
}

@inproceedings{sartin_approximation_2013,
  title = {Approximation of Hyperbolic Tangent Activation Function Using Hybrid Methods},
  booktitle = {2013 8th {{International Workshop}} on {{Reconfigurable}} and {{Communication}}-{{Centric Systems}}-on-{{Chip}} ({{ReCoSoC}})},
  author = {Sartin, M. A. and da Silva, A. C. R.},
  year = {2013},
  month = jul,
  pages = {1--6},
  doi = {10.1109/ReCoSoC.2013.6581545},
  abstract = {Artificial Neural Networks are widely used in various applications in engineering, as such solutions of nonlinear problems. The implementation of this technique in reconfigurable devices is a great challenge to researchers by several factors, such as floating point precision, nonlinear activation function, performance and area used in FPGA. The contribution of this work is the approximation of a nonlinear function used in ANN, the popular hyperbolic tangent activation function. The system architecture is composed of several scenarios that provide a tradeoff of performance, precision and area used in FPGA. The results are compared in different scenarios and with current literature on error analysis, area and system performance.},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\3C4ZRCCQ\\6581545.html:text/html},
  timestamp = {2019-05-06T19:56:07Z}
}

@article{saulMeanFieldTheory1996,
  title = {Mean Field Theory for Sigmoid Belief Networks},
  author = {Saul, Lawrence K. and Jaakkola, Tommi and Jordan, Michael I.},
  year = {1996},
  volume = {4},
  pages = {61--76},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\V89VH56N\\Saul et al. - 1996 - Mean field theory for sigmoid belief networks.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ZE7NYWSH\\10156.html:text/html},
  journal = {Journal of artificial intelligence research},
  timestamp = {2020-11-29T11:29:12Z}
}

@article{schmidhuberDeepLearningNeural2015,
  title = {Deep Learning in Neural Networks: {{An}} Overview},
  shorttitle = {Deep Learning in Neural Networks},
  author = {Schmidhuber, J{\"u}rgen},
  year = {2015},
  month = jan,
  volume = {61},
  pages = {85--117},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2014.09.003},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  file = {Submitted Version:C\:\\Users\\SomefunAgba\\Zotero\\storage\\HGPQSSB2\\Schmidhuber - 2015 - Deep learning in neural networks An overview.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\AR2SSVJC\\S0893608014002135.html:text/html},
  journal = {Neural Networks},
  language = {en},
  timestamp = {2020-07-06T05:17:08Z}
}

@article{sejnowskiUnreasonableEffectivenessDeep2020,
  title = {The Unreasonable Effectiveness of Deep Learning in Artificial Intelligence},
  author = {Sejnowski, Terrence J.},
  year = {2020},
  month = dec,
  volume = {117},
  pages = {30033--30038},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1907373117},
  abstract = {Deep learning networks have been trained to recognize speech, caption photographs, and translate text between languages at high levels of performance. Although applications of deep learning networks to real-world problems have become ubiquitous, our understanding of why they are so effective is lacking. These empirical results should not be possible according to sample complexity in statistics and nonconvex optimization theory. However, paradoxes in the training and effectiveness of deep learning networks are being investigated and insights are being found in the geometry of high-dimensional spaces. A mathematical theory of deep learning would illuminate how they function, allow us to assess the strengths and weaknesses of different network architectures, and lead to major improvements. Deep learning has provided natural ways for humans to communicate with digital devices and is foundational for building artificial general intelligence. Deep learning was inspired by the architecture of the cerebral cortex and insights into autonomy and general intelligence may be found in other brain regions that are essential for planning and survival, but major breakthroughs will be needed to achieve these goals.},
  chapter = {Colloquium Paper},
  copyright = {\textcopyright{} 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\2TLSGRZ8\\Sejnowski - 2020 - The unreasonable effectiveness of deep learning in.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\63XCUQZ5\\30033.html:text/html;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\M5I8GUA2\\30033.html:text/html},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {48},
  pmid = {31992643},
  timestamp = {2020-12-09T19:55:25Z}
}

@article{shaoNonlinearTrackingDifferentiator20140901,
  title = {{Nonlinear tracking differentiator based on improved sigmoid function}},
  author = {Shao, Xingling and Wang, Honglun},
  year = {20140901},
  volume = {31},
  pages = {1116--1122},
  doi = {10.7641/CTA.2014.31117},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\7GMPRNMM\\view_abstract.html:text/html},
  journal = {Control Theory and Application},
  language = {cn},
  number = {8},
  timestamp = {2020-09-27T01:35:27Z}
}

@article{sharifianVelocityControlDC2009,
  title = {Velocity {{Control}} of {{DC Motor Based Intelligent Methods}} and {{Optimal Integral State Feed Back Controller}}},
  author = {Sharifian, M.B.B. and Rahnavard, R. and Delavari, H.},
  year = {2009},
  pages = {81--84},
  issn = {17938201},
  doi = {10.7763/IJCTE.2009.V1.13},
  journal = {International Journal of Computer Theory and Engineering},
  timestamp = {2019-08-18T03:11:07Z}
}

@incollection{sharmaIntelligentAdaptiveFuzzy2018,
  title = {Intelligent {{Adaptive Fuzzy Control}}},
  booktitle = {Intelligent {{Control}}},
  author = {Sharma, Kaushik Das and Chatterjee, Amitava and Rakshit, Anjan},
  year = {2018},
  pages = {3--21},
  publisher = {{Springer}},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\YJYUW3ZZ\\978-981-13-1298-4_1.html:text/html},
  timestamp = {2019-08-03T04:42:53Z}
}

@article{shenLogisticGrowthModelling2020,
  title = {Logistic Growth Modelling of {{COVID}}-19 Proliferation in {{China}} and Its International Implications},
  author = {Shen, Christopher Y.},
  year = {2020},
  month = jul,
  volume = {96},
  pages = {582--589},
  issn = {1201-9712},
  doi = {10.1016/j.ijid.2020.04.085},
  abstract = {Objective As the coronavirus disease 2019 (COVID-19) pandemic continues to proliferate globally, this paper shares the findings of modelling the outbreak in China at both provincial and national levels. This paper examines the applicability of the logistic growth model, with implications for the study of the COVID-19 pandemic and other infectious diseases. Methods An NLS (Non-Linear Least Squares) method was employed to estimate the parameters of a differentiated logistic growth function using new daily COVID-19 cases in multiple regions in China and in other selected countries. The estimation was based upon training data from January 20, 2020 to March 13, 2020. A restriction test was subsequently implemented to examine whether a designated parameter was identical among regions or countries, and the diagnosis of residuals was also conducted. The model's goodness of fit was checked using testing data from March 14, 2020 to April 18, 2020. Results The model presented in this paper fitted time-series data exceedingly well for the whole of China, its eleven selected provinces and municipalities, and two other countries - South Korea and Iran - and provided estimates of key parameters. This study rejected the null hypothesis that the growth rates of outbreaks were the same among ten selected non-Hubei provinces in China, as well as between South Korea and Iran. The study found that the model did not provide reliable estimates for countries that were in the early stages of outbreaks. Furthermore, this study concured that the R2 values might vary and mislead when compared between different portions of the same non-linear curve. In addition, the study identified the existence of heteroskedasticity and positive serial correlation within residuals in some provinces and countries. Conclusions The findings suggest that there is potential for this model to contribute to better public health policy in combatting COVID-19. The model does so by providing a simple logistic framework for retrospectively analyzing outbreaks in regions that have already experienced a maximal proliferation in cases. Based upon statistical findings, this study also outlines certain challenges in modelling and their implications for the results.},
  file = {ScienceDirect Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\3TYAKJ3F\\Shen - 2020 - Logistic growth modelling of COVID-19 proliferatio.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\NHR2R627\\S1201971220303039.html:text/html},
  journal = {International Journal of Infectious Diseases},
  language = {en},
  timestamp = {2020-10-19T06:21:16Z}
}

@article{shulmanMathAliveUsingOriginal1998,
  title = {Math-{{Alive}}! {{Using Original Sources To Teach Mathematics In Social Context}}},
  author = {Shulman, Bonnie},
  year = {1998},
  month = jan,
  volume = {8},
  pages = {1--14},
  issn = {1051-1970, 1935-4053},
  doi = {10.1080/10511979808965879},
  journal = {PRIMUS},
  language = {en},
  number = {1},
  timestamp = {2020-11-30T06:39:49Z}
}

@article{simardBestPracticesConvolutional2003,
  title = {Best {{Practices}} for {{Convolutional Neural Networks Applied}} to {{Visual Document Analysis}}},
  author = {Simard, Patrice Y. and Steinkraus, Dave and Platt, John},
  year = {2003},
  month = aug,
  url = {https://www.microsoft.com/en-us/research/publication/best-practices-for-convolutional-neural-networks-applied-to-visual-document-analysis/},
  urldate = {2020-10-20},
  abstract = {Neural networks are a powerful technology for classification of visual inputs arising from documents. However, there is a confusing plethora of different neural network methods that are used in the literature and in industry. This paper describes a set of concrete best practices that document analysis researchers can use to get good results with neural [\ldots ]},
  file = {Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\AY2WWBA7\\Simard et al. - 2003 - Best Practices for Convolutional Neural Networks A.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\6T2F3UVD\\best-practices-for-convolutional-neural-networks-applied-to-visual-document-analysis.html:text/html},
  language = {en-US},
  timestamp = {2020-10-20T09:49:55Z}
}

@book{sobhani-tehraniFaultDiagnosisNonlinear2009,
  title = {Fault {{Diagnosis}} of {{Nonlinear Systems Using}} a {{Hybrid Approach}}},
  author = {{Sobhani-Tehrani}, Ehsan and Khorasani, Khashayar},
  year = {2009},
  month = jun,
  publisher = {{Springer Science \& Business Media}},
  abstract = {Theincreasingcomplexityofspacevehiclessuchassatellites,andthecostreduction measures that have affected satellite operators are increasingly driving the need for more autonomy in satellite diagnostics and control systems. Current methods for detecting and correcting anomalies onboard the spacecraft as well as on the ground are primarily manual and labor intensive, and therefore, tend to be slow. Operators inspect telemetry data to determine the current satellite health. They use various statisticaltechniques andmodels,buttheanalysisandevaluation ofthelargevolume of data still require extensive human intervention and expertise that is prone to error. Furthermore, for spacecraft and most of these satellites, there can be potentially unduly long delays in round-trip communications between the ground station and the satellite. In this context, it is desirable to have onboard fault-diagnosis system that is capable of detecting, isolating, identifying or classifying faults in the system withouttheinvolvementandinterventionofoperators.Towardthisend,theprinciple goal here is to improve the ef?ciency, accuracy, and reliability of the trend analysis and diagnostics techniques through utilization of intelligent-based and hybrid-based methodologies.},
  googlebooks = {6OH0GX1oQd8C},
  isbn = {978-0-387-92906-4},
  language = {en},
  timestamp = {2019-08-04T03:22:06Z}
}

@inproceedings{somefunetalnlsigcovid19tyanconf2020,
  title = {On the Nlogistic-Sigmoid Modelling for Complex Growth Processes: In Application to the {{COVID}}-19 Pandemic},
  booktitle = {6th {{TYAN International Thematic Workshop}} on {{Data Science}} for {{Solution}}-Driven and {{Sustainable Response}} to Current Developing World Challenges},
  author = {{Somefun} and O. A., Akingbade, K. F. and Dahunsi, F. M.},
  year = {2020},
  month = dec,
  timestamp = {2020-12-08T13:30:35Z}
}

@article{somefunLogisticsigmoidNlogisticsigmoidModelling2020,
  title = {From the Logistic-Sigmoid to Nlogistic-Sigmoid: Modelling the {{COVID}}-19 Pandemic Growth},
  author = {Somefun, Oluwasegun A. and Akingbade, Kayode and Dahunsi, Folasade},
  year = {2020},
  month = dec,
  url = {http://arxiv.org/abs/2008.04210},
  urldate = {2020-12-15},
  archivePrefix = {arXiv},
  eprint = {2008.04210},
  eprinttype = {arxiv},
  journal = {arXiv:2008.04210 [cs]},
  primaryClass = {cs},
  timestamp = {2020-12-15T21:51:35Z}
}

@misc{somefunSomefunAgbaNLSIGCOVID19Lab2020,
  title = {{{somefunAgba}}/{{NLSIG}}\_{{COVID19Lab}}},
  author = {Somefun, Oluwasegun},
  year = {2020},
  month = dec,
  url = {https://github.com/somefunAgba/NLSIG_COVID19Lab},
  urldate = {2020-12-08},
  abstract = {A nlogistic-sigmoid modelling laboratory for the COVID-19 pandemic growth},
  copyright = {AGPL},
  timestamp = {2020-12-08T13:26:41Z}
}

@inproceedings{sopenaNeuralNetworksPeriodic1999,
  title = {Neural Networks with Periodic and Monotonic Activation Functions: A Comparative Study in Classification Problems},
  shorttitle = {Neural Networks with Periodic and Monotonic Activation Functions},
  booktitle = {9th {{International Conference}} on {{Artificial Neural Networks}}: {{ICANN}} '99},
  author = {Sopena, J.M.},
  year = {1999},
  volume = {1999},
  pages = {323--328},
  publisher = {{IEE}},
  address = {{Edinburgh, UK}},
  doi = {10.1049/cp:19991129},
  isbn = {978-0-85296-721-8},
  language = {en},
  timestamp = {2019-07-29T18:28:32Z}
}

@book{stanoyevitchIntroductionNumericalOrdinary2004,
  title = {Introduction to {{Numerical Ordinary}} and {{Partial Differential Equations Using MATLAB}}},
  author = {Stanoyevitch, Alexander},
  year = {2004},
  edition = {First},
  publisher = {{Wiley-Interscience}},
  url = {http://gen.lib.rus.ec/book/index.php?md5=9244d0623ceffcefe98fbd10aa7f0116},
  urldate = {2019-08-04},
  isbn = {978-0-471-69738-1},
  series = {Pure and {{Applied Mathematics}}: {{A Wiley Series}} of {{Texts}}, {{Monographs}} and {{Tracts}}},
  timestamp = {2019-08-04T17:26:12Z}
}

@article{szeEfficientProcessingDeep2017,
  title = {Efficient {{Processing}} of {{Deep Neural Networks}}: {{A Tutorial}} and {{Survey}}},
  shorttitle = {Efficient {{Processing}} of {{Deep Neural Networks}}},
  author = {Sze, Vivienne and Chen, YuHsin and Yang, TienJu and Emer, Joel S.},
  year = {2017},
  month = dec,
  volume = {105},
  pages = {2295--2329},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2017.2761740},
  abstract = {Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances toward the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic codesigns, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the tradeoffs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.},
  journal = {Proceedings of the IEEE},
  number = {12},
  timestamp = {2020-09-27T02:18:23Z}
}

@article{tabatabaiHyperbolasticGrowthModels2005,
  title = {Hyperbolastic Growth Models: Theory and Application},
  shorttitle = {Hyperbolastic Growth Models},
  author = {Tabatabai, Mohammad and Williams, David Keith and Bursac, Zoran},
  year = {2005},
  month = mar,
  volume = {2},
  pages = {14},
  issn = {1742-4682},
  doi = {10.1186/1742-4682-2-14},
  abstract = {Mathematical models describing growth kinetics are very important for predicting many biological phenomena such as tumor volume, speed of disease progression, and determination of an optimal radiation and/or chemotherapy schedule. Growth models such as logistic, Gompertz, Richards, and Weibull have been extensively studied and applied to a wide range of medical and biological studies. We introduce a class of three and four parameter models called "hyperbolastic models" for accurately predicting and analyzing self-limited growth behavior that occurs e.g. in tumors. To illustrate the application and utility of these models and to gain a more complete understanding of them, we apply them to two sets of data considered in previously published literature.},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\XIKVJWTB\\Tabatabai et al. - 2005 - Hyperbolastic growth models theory and applicatio.pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\KSFFZDZF\\1742-4682-2-14.html:text/html;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\Q84DQTXQ\\1742-4682-2-14.html:text/html},
  journal = {Theoretical Biology and Medical Modelling},
  number = {1},
  timestamp = {2020-11-30T07:31:31Z}
}

@article{tan_comparative_2014,
  title = {A Comparative Investigation of Non-Linear Activation Functions in Neural Controllers for Search-Based Game {{AI}} Engineering},
  author = {Tan, Tse Guan and Teo, Jason and Anthony, Patricia},
  year = {2014},
  month = jan,
  volume = {41},
  pages = {1--25},
  issn = {1573-7462},
  doi = {10.1007/s10462-011-9294-y},
  abstract = {The creation of intelligent video game controllers has recently become one of the greatest challenges in game artificial intelligence research, and it is arguably one of the fastest-growing areas in game design and development. The learning process, a very important feature of intelligent methods, is the result of an intelligent game controller to determine and control the game objects behaviors' or actions autonomously. Our approach is to use a more efficient learning model in the form of artificial neural networks for training the controllers. We propose a Hill-Climbing Neural Network (HillClimbNet) that controls the movement of the Ms. Pac-man agent to travel around the maze, gobble all of the pills and escape from the ghosts in the maze. HillClimbNet combines the hill-climbing strategy with a simple, feed-forward artificial neural network architecture. The aim of this study is to analyze the performance of various activation functions for the purpose of generating neural-based controllers to play a video game. Each non-linear activation function is applied identically for all the nodes in the network, namely log-sigmoid, logarithmic, hyperbolic tangent-sigmoid and Gaussian. In general, the results shows an optimum configuration is achieved by using log-sigmoid, while Gaussian is the worst activation function.},
  journal = {Artificial Intelligence Review},
  language = {en},
  number = {1},
  timestamp = {2019-05-06T19:56:04Z}
}

@article{taylorForecastingScale2018,
  title = {Forecasting at {{Scale}}},
  author = {Taylor, Sean J. and Letham, Benjamin},
  year = {2018},
  month = jan,
  volume = {72},
  pages = {37--45},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1380080},
  abstract = {Forecasting is a common data science task that helps organizations with capacity planning, goal setting, and anomaly detection. Despite its importance, there are serious challenges associated with producing reliable and high-quality forecasts\textemdash especially when there are a variety of time series and analysts with expertise in time series modeling are relatively rare. To address these challenges, we describe a practical approach to forecasting ``at scale'' that combines configurable models with analyst-in-the-loop performance analysis. We propose a modular regression model with interpretable parameters that can be intuitively adjusted by analysts with domain knowledge about the time series. We describe performance analyses to compare and evaluate forecasting procedures, and automatically flag forecasts for manual review and adjustment. Tools that help analysts to use their expertise most effectively enable reliable, practical forecasting of business time series.},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2017.1380080},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\EK9U7R6Z\\00031305.2017.html:text/html},
  journal = {The American Statistician},
  number = {1},
  timestamp = {2020-11-29T12:48:05Z}
}

@article{timmonsApproximatingActivationFunctions2020,
  title = {Approximating {{Activation Functions}}},
  author = {Timmons, Nicholas Gerard and Rice, Andrew},
  year = {2020},
  month = jan,
  url = {http://arxiv.org/abs/2001.06370},
  urldate = {2020-07-06},
  abstract = {ReLU is widely seen as the default choice for activation functions in neural networks. However, there are cases where more complicated functions are required. In particular, recurrent neural networks (such as LSTMs) make extensive use of both hyperbolic tangent and sigmoid functions. These functions are expensive to compute. We used function approximation techniques to develop replacements for these functions and evaluated them empirically on three popular network configurations. We find safe approximations that yield a 10\% to 37\% improvement in training times on the CPU. These approximations were suitable for all cases we considered and we believe are appropriate replacements for all networks using these activation functions. We also develop ranged approximations which only apply in some cases due to restrictions on their input domain. Our ranged approximations yield a performance improvement of 20\% to 53\% in network training time. Our functions also match or considerably out perform the ad-hoc approximations used in Theano and the implementation of Word2Vec.},
  archivePrefix = {arXiv},
  eprint = {2001.06370},
  eprinttype = {arxiv},
  file = {arXiv Fulltext PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\AAGWRU9P\\Timmons and Rice - 2020 - Approximating Activation Functions.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\3W6KVZ7B\\2001.html:text/html},
  journal = {arXiv:2001.06370 [cs, stat]},
  primaryClass = {cs, stat},
  timestamp = {2020-07-06T04:57:40Z}
}

@article{udellMaximizingSumSigmoids2013,
  title = {Maximizing a Sum of Sigmoids},
  author = {Udell, Madeleine and Boyd, Stephen},
  year = {2013},
  pages = {1--25},
  publisher = {{Citeseer}},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\S3KXSR3L\\Udell and Boyd - 2013 - Maximizing a sum of sigmoids.pdf:application/pdf},
  journal = {Optimization and Engineering},
  timestamp = {2020-11-29T11:29:12Z}
}

@article{uedaImprovementSignaltonoiseRatio2010,
  title = {Improvement of Signal-to-Noise Ratio by Stochastic Resonance in Sigmoid Function Threshold Systems, Demonstrated Using a {{CMOS}} Inverter},
  author = {Ueda, Michihito},
  year = {2010},
  volume = {389},
  pages = {1978--1985},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\XULB5W5V\\S0378437110000890.html:text/html},
  journal = {Physica A: Statistical Mechanics and its Applications},
  number = {10},
  timestamp = {2019-08-04T03:08:36Z}
}

@book{vasArtificialIntelligencebasedElectricalMachines1999,
  title = {Artificial-{{Intelligence}}-Based {{Electrical Machines}} and {{Drives}}: {{Application}} of {{Fuzzy}}, {{Neural}}, {{Fuzzy}}-Neural, and {{Genetic}}-Algorithm-Based {{Techniques}}},
  shorttitle = {Artificial-{{Intelligence}}-Based {{Electrical Machines}} and {{Drives}}},
  author = {Vas, Peter},
  year = {1999},
  month = jan,
  publisher = {{Oxford University Press}},
  address = {{Oxford, New York}},
  abstract = {Recently artificial-intelligence-based techniques (fuzzy logic, neural networks, fuzzy-neural networks, genetic algorithms, etc) have received increased attention world-wide and at present two industrial drives incorporate some form of artificial intelligence. This is the first comprehensive book which discusses numerous AI applications to electrical machines and drives. The drives considered are: d.c. drives, induction motor drives, synchronous motor drives, and switched reluctance motor drives. Sensorless drives are also considered. It is essential reading for anyone interested in acquiring a solid background in AI-based electrical machines and drives. It presents a detailed and unified mathematical and physical treatment.},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\VV528QBB\\artificial-intelligence-based-electrical-machines-and-drives-9780198593973.html:text/html},
  isbn = {978-0-19-859397-3},
  series = {Monographs in {{Electrical}} and {{Electronic Engineering}}},
  timestamp = {2019-08-04T03:15:24Z}
}

@book{waadelandContinuedFractions2008,
  title = {Continued {{Fractions}}},
  author = {Waadeland, Haakon and Lorentzen, Lisa},
  year = {2008},
  publisher = {{Atlantis Press}},
  url = {https://www.springer.com/gb/book/9789491216374},
  urldate = {2019-05-11},
  abstract = {Continued Fractions consists of two volumes \textemdash{} Volume 1: Convergence Theory; and Volume 2: Representation of Functions (tentative title), which is expected in 2011. Volume 1 is dedicated to the convergence and computation of continued fractions, while Volume 2 will treat representations of meromorphic functions by continued fractions. Taken together, the two volumes will present the basic continued fractions theory without requiring too much previous knowledge; some basic knowledge of complex functions will suffice. Both new and advanced graduate students of continued fractions shall get a comprehensive understanding of how these infinite structures work in a number of applications, and why they work so well. A varied buffet of possible applications to whet the appetite is presented first, before the more basic but modernized theory is given. This new edition is the result of an increasing interest in computing special functions by means of continued fractions. The methods described in detail are, in many cases, very simple, yet reliable and efficient.},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\C4X7WBKZ\\9789491216374.html:text/html},
  isbn = {978-94-91216-37-4},
  language = {en},
  series = {Atlantis {{Studies}} in {{Mathematics}} for {{Engineering}} and {{Science}}},
  timestamp = {2019-08-04T06:19:56Z}
}

@article{weiTwosampleDvoretzkyKiefer2012,
  title = {Two-Sample {{Dvoretzky}}\textendash{{Kiefer}}\textendash{{Wolfowitz}} Inequalities},
  author = {Wei, Fan and Dudley, Richard M.},
  year = {2012},
  month = mar,
  volume = {82},
  pages = {636--644},
  issn = {0167-7152},
  doi = {10.1016/j.spl.2011.11.012},
  abstract = {The Dvoretzky\textendash Kiefer\textendash Wolfowitz (DKW) inequality says that if Fn is an empirical distribution function for variables i.i.d.~with a distribution function F, and Kn is the Kolmogorov statistic nsupx|(Fn-F)(x)|, then there is a constant C such that for any M{$>$}0, Pr(Kn{$>$}M){$\leq$}Cexp(-2M2). Massart proved that one can take C=2 (DKWM inequality), which is sharp for F continuous. We consider the analogous Kolmogorov\textendash Smirnov statistic for the two-sample case and show that for m=n, the DKW inequality holds for n{$\geq$}n0 for some C depending on n0, with C=2 if and only if n0{$\geq$}458. The DKWM inequality fails for the three pairs (m,n) with 1{$\leq$}m},
  file = {ScienceDirect Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\NBP9XI4J\\S0167715211003658.html:text/html},
  journal = {Statistics \& Probability Letters},
  language = {en},
  number = {3},
  timestamp = {2020-12-15T21:33:35Z}
}

@article{werbosBackpropagationTimeWhat1990,
  title = {Backpropagation through Time: What It Does and How to Do It},
  shorttitle = {Backpropagation through Time},
  author = {Werbos, P.J.},
  year = {1990},
  month = oct,
  volume = {78},
  pages = {1550--1560},
  issn = {1558-2256},
  doi = {10.1109/5.58337},
  abstract = {Basic backpropagation, which is a simple method now being widely used in areas like pattern recognition and fault diagnosis, is reviewed. The basic equations for backpropagation through time, and applications to areas like pattern recognition involving dynamic systems, systems identification, and control are discussed. Further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations, or true recurrent networks, and other practical issues arising with the method are described. Pseudocode is provided to clarify the algorithms. The chain rule for ordered derivatives-the theorem which underlies backpropagation-is briefly discussed. The focus is on designing a simpler version of backpropagation which can be translated into computer code and applied directly by neutral network users.{$<>$}},
  file = {Submitted Version:C\:\\Users\\SomefunAgba\\Zotero\\storage\\RSP75T33\\Werbos - 1990 - Backpropagation through time what it does and how.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\Z7PF57UQ\\58337.html:text/html},
  journal = {Proceedings of the IEEE},
  number = {10},
  timestamp = {2020-07-09T07:13:32Z}
}

@misc{WHOCoronavirusDisease2020,
  title = {{{WHO Coronavirus Disease}} ({{COVID}}-19) {{Dashboard}}},
  year = {2020},
  url = {https://covid19.who.int},
  urldate = {2020-10-21},
  abstract = {World Health Organization Coronavirus disease situation dashboard presents official daily counts of COVID-19 cases and deaths worldwide, while providing a hub to other resources. Interactive tools, including maps, epidemic curves and other charts and graphics, with downloadable data, allow users to track and explore the latest trends, numbers and statistics at global, regional and country levels.},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\PW2997UU\\covid19.who.int.html:text/html},
  journal = {World Health Organization},
  language = {en},
  timestamp = {2020-10-21T21:58:52Z}
}

@article{wuGeneralizedLogisticGrowth2020,
  title = {Generalized Logistic Growth Modeling of the {{COVID}}-19 Outbreak: Comparing the Dynamics in the 29 Provinces in {{China}} and in the Rest of the World},
  shorttitle = {Generalized Logistic Growth Modeling of the {{COVID}}-19 Outbreak},
  author = {Wu, Ke and Darcet, Didier and Wang, Qian and Sornette, Didier},
  year = {2020},
  month = aug,
  volume = {101},
  pages = {1561--1581},
  issn = {1573-269X},
  doi = {10.1007/s11071-020-05862-6},
  abstract = {Started in Wuhan, China, the COVID-19 has been spreading all over the world. We calibrate the logistic growth model, the generalized logistic growth model, the generalized Richards model and the generalized growth model to the reported number of infected cases for the whole of China, 29 provinces in China, and 33 countries and regions that have been or are undergoing major outbreaks. We dissect the development of the epidemics in China and the impact of the drastic control measures both at the aggregate level and within each province. We quantitatively document four phases of the outbreak in China with a detailed analysis on the heterogeneous situations across provinces. The extreme containment measures implemented by China were very effective with some instructive variations across provinces. Borrowing from the experience of China, we made scenario projections on the development of the outbreak in other countries. We identified that outbreaks in 14 countries (mostly in western Europe) have ended, while resurgences of cases have been identified in several among them. The modeling results clearly show longer after-peak trajectories in western countries, in contrast to most provinces in China where the after-peak trajectory is characterized by a much faster decay. We identified three groups of countries in different level of outbreak progress, and provide informative implications for the current global pandemic.},
  file = {Springer Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\IYKB3SLV\\Wu et al. - 2020 - Generalized logistic growth modeling of the COVID-.pdf:application/pdf},
  journal = {Nonlinear Dynamics},
  language = {en},
  number = {3},
  timestamp = {2020-10-19T05:45:16Z}
}

@inproceedings{wuraola_sqnl_2018,
  title = {{{SQNL}}: {{A New Computationally Efficient Activation Function}}},
  shorttitle = {{{SQNL}}},
  booktitle = {2018 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Wuraola, A. and Patel, N.},
  year = {2018},
  month = jul,
  pages = {1--7},
  doi = {10.1109/IJCNN.2018.8489043},
  abstract = {A new activation function is proposed. This activation function uses the square operator to introduce the required non-linearity as compared with the use of an exponential term in the popular TanSig. Smaller computational operation count characterizes the proposed activation function. The key to the effectiveness of this function is a faster convergence when used in Multilayer Perceptron Artificial Neural Network architectural problems. Besides, the derivative of the function is linear, resulting in a quicker gradient computation. The effectiveness and efficiency of the proposed activation function have been compared with the TanSig and the computationally efficient ElliotSig functions using selected UCI datasets. The MNIST handwritten dataset was also used to show the ability of this function on more massive datasets. An empirical comparison suggests that the proposed function outperforms TanSig and ElliotSig in convergence time as well as in generalization metrics for most datasets.},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\AD2B85GD\\8489043.html:text/html},
  timestamp = {2019-05-06T20:05:17Z}
}

@article{xsRichardsModelRevisited2012,
  title = {Richards Model Revisited: Validation by and Application to Infection Dynamics},
  shorttitle = {Richards Model Revisited},
  author = {Xs, Wang and J, Wu and Y, Yang},
  year = {2012},
  month = nov,
  volume = {313},
  publisher = {{J Theor Biol}},
  issn = {1095-8541},
  doi = {10.1016/j.jtbi.2012.07.024},
  abstract = {Ever since Richards proposed his flexible growth function more than half a century ago, it has been a mystery that this empirical function has made many incredible coincidences with real ecological or epidemic data even though one of its parameters (i.e., the exponential term) does not seem to have \ldots},
  file = {Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\S76JDWH5\\22889641.html:text/html},
  journal = {Journal of theoretical biology},
  language = {en},
  pmid = {22889641},
  timestamp = {2020-10-22T10:01:17Z}
}

@article{yasienChatteringAttenuationSliding2009,
  title = {Chattering {{Attenuation}} of {{Sliding Mode Controller Using Genetic Algorithm}} and {{Fuzzy Logic Techniques}}},
  author = {Yasien, Farzdaq R. and Kadhim, Mina Q.},
  year = {2009},
  volume = {27},
  pages = {2595--2610},
  file = {Full Text:C\:\\Users\\SomefunAgba\\Zotero\\storage\\9FQAJCGY\\Yasien and Kadhim - 2009 - Chattering Attenuation of Sliding Mode Controller .pdf:application/pdf;Snapshot:C\:\\Users\\SomefunAgba\\Zotero\\storage\\7I3CD97D\\iasj.html:text/html},
  journal = {Engineering and Technology Journal},
  number = {14},
  timestamp = {2019-08-03T04:43:54Z}
}

@inproceedings{yeoModellingTechniqueUtilizing2016,
  title = {Modelling Technique Utilizing Modified Sigmoid Functions for Describing Power Transistor Device Capacitances Applied on {{GaN HEMT}} and Silicon {{MOSFET}}},
  booktitle = {2016 {{IEEE Applied Power Electronics Conference}} and {{Exposition}} ({{APEC}})},
  author = {Yeo, H. L. and Tseng, K. J.},
  year = {2016},
  month = mar,
  pages = {3107--3114},
  doi = {10.1109/APEC.2016.7468308},
  abstract = {In power transistor models, it is very important that device capacitances are modelled accurately so that switching losses, EMI filter requirements and gate timing requirements of the converter can be accurately determined. In this paper, a modelling technique utilizing modified sigmoid functions to describe the device capacitances is applied on a GaN HEMT and a silicon MOSFET to develop their corresponding SPICE models. Comparison of switching energies of the transistors under slow-switching conditions suggest that the technique is suitable for modelling both types of transistors. The developed model for the GaN HEMT is also shown to simulate faster than the manufacturer's model under fast switching conditions.},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\JVJSI8ZZ\\7468308.html:text/html},
  timestamp = {2019-08-03T05:40:13Z}
}

@article{yinFlexibleSigmoidFunction2003,
  title = {A {{Flexible Sigmoid Function}} of {{Determinate Growth}}},
  author = {Yin, Xinyou and Goudriaan, Jan and Lantinga, Egbert A. and Vos, Jan and Spiertz, Huub J.},
  year = {2003},
  month = feb,
  volume = {91},
  pages = {361--371},
  issn = {0305-7364},
  doi = {10.1093/aob/mcg029},
  abstract = {A new empirical equation for the sigmoid pattern of determinate growth, `the beta growth function', is presented. It calculates weight (w) in dependence of time, using the following three parameters: tm, the time at which the maximum growth rate is obtained; te, the time at the end of growth; and wmax, the maximal value for w, which is achieved at te. The beta growth function was compared with four classical (logistic, Richards, Gompertz and Weibull) growth equations, and two expolinear equations. All equations described successfully the sigmoid dynamics of seed filling, plant growth and crop biomass production. However, differences were found in estimating wmax. Features of the beta function are: (1) like the Richards equation it is flexible in describing various asymmetrical sigmoid patterns (its symmetrical form is a cubic polynomial); (2) like the logistic and the Gompertz equations its parameters are numerically stable in statistical estimation; (3) like the Weibull function it predicts zero mass at time zero, but its extension to deal with various initial conditions can be easily obtained; (4) relative to the truncated expolinear equation it provides more reasonable estimates of final quantity and duration of a growth process. In addition, the new function predicts a zero growth rate at both the start and end of a precisely defined growth period. Therefore, it is unique for dealing with determinate growth, and is more suitable than other functions for embedding in process-based crop simulation models to describe the dynamics of organs as sinks to absorb assimilates. Because its parameters correspond to growth traits of interest to crop scientists, the beta growth function is suitable for characterization of environmental and genotypic influences on growth processes. However, it is not suitable for estimating maximum relative growth rate to characterize early growth that is expected to be close to exponential.},
  file = {PubMed Central Full Text PDF:C\:\\Users\\SomefunAgba\\Zotero\\storage\\ZNSNM4NC\\YIN et al. - 2003 - A Flexible Sigmoid Function of Determinate Growth.pdf:application/pdf},
  journal = {Annals of Botany},
  number = {3},
  pmcid = {PMC4244967},
  pmid = {12547689},
  timestamp = {2020-11-29T12:24:59Z}
}

@article{zamanlooy_efficient_2014,
  title = {Efficient {{VLSI Implementation}} of {{Neural Networks With Hyperbolic Tangent Activation Function}}},
  author = {Zamanlooy, B. and Mirhassani, M.},
  year = {2014},
  month = jan,
  volume = {22},
  pages = {39--48},
  issn = {1063-8210},
  doi = {10.1109/TVLSI.2012.2232321},
  abstract = {Nonlinear activation function is one of the main building blocks of artificial neural networks. Hyperbolic tangent and sigmoid are the most used nonlinear activation functions. Accurate implementation of these transfer functions in digital networks faces certain challenges. In this paper, an efficient approximation scheme for hyperbolic tangent function is proposed. The approximation is based on a mathematical analysis considering the maximum allowable error as design parameter. Hardware implementation of the proposed approximation scheme is presented, which shows that the proposed structure compares favorably with previous architectures in terms of area and delay. The proposed structure requires less output bits for the same maximum allowable error when compared to the state-of-the-art. The number of output bits of the activation function determines the bit width of multipliers and adders in the network. Therefore, the proposed activation function results in reduction in area, delay, and power in VLSI implementation of artificial neural networks with hyperbolic tangent activation function.},
  file = {IEEE Xplore Abstract Record:C\:\\Users\\SomefunAgba\\Zotero\\storage\\5F3Q3EGD\\6409494.html:text/html},
  journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
  number = {1},
  timestamp = {2019-05-06T20:10:56Z}
}


